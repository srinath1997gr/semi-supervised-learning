{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#3665af\">Semi-Supervised Learning </span>\n",
    "<hr>\n",
    "\n",
    "###### Goal\n",
    "In this assignment, we will explore the concepts and techniques of semi-supervised learning.\n",
    "\n",
    "###### Prerequisites\n",
    "This assignment has the following dependencies:\n",
    "- Jupyter Notebook, along with the following libraries (which should be installed on the Computing Platform):\n",
    "  - Scikit Learn\n",
    "  - Numpy\n",
    "  - os\n",
    "\n",
    "Let's dive into the world of semi-supervised learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:30px;color:#3665af;background-color:#E9E9F5;padding:10px;\">Assignment Hands-on "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:20px;color:#F1F8FC;background-color:#0095EA;padding:10px;\"> Import libraries </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (Dense,\n",
    "                                     Flatten,\n",
    "                                     Dropout,\n",
    "                                     BatchNormalization,\n",
    "                                     Conv2D,\n",
    "                                     MaxPooling2D,)\n",
    "from tensorflow.keras.regularizers import l2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:20px;color:#F1F8FC;background-color:#0095EA;padding:10px;\"> Learn more about the data </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we are working with data collected from two different view from same region via satellite technology to study the Arctic region. These two data types offer valuable insights into various sea ice types, thereby enhancing navigation in the Arctic.\n",
    "\n",
    "1. **Sentinel-1 Data (view 1):** We use Synthetic Aperture Radar (SAR) satellite images from the Sentinel-1 mission. SAR images are incredibly useful for creating sea ice charts in the Arctic. SAR works by sending radar signals to the Earth's surface and capturing the signals that bounce back. One specific view we're utilizing is the Sentinel-1 image captured in HH polarization. This view helps us understand the characteristics of the sea ice in the Arctic. if you want to know more about it here is the [link](https://en.wikipedia.org/wiki/Sentinel-1).\n",
    "\n",
    "2. **AMSR2 Data (view 2):** Alongside each Sentinel-1 image, we have corresponding data from the Advanced Microwave Scanning Radiometer 2 (AMSR2). This dataset contains information about the brightness temperatures of the Earth's surface. AMSR2 measures microwave radiation, which can be used to gather information about surface properties like sea ice concentration. if you want to know more about it here is the [link](https://www.ospo.noaa.gov/Products/atmosphere/gpds/about_amsr2.html).\n",
    "\n",
    "To further analyze these datasets, we selected 10 files and divided the images into smaller patches, each patch 32 by 32 pixels. This patches allows us to focus on specific areas of interest within the Arctic and study them in detail. By combining the information from both Sentinel-1 and AMSR2 data, we can gain a comprehensive understanding of the Arctic environment and its sea ice patterns, which is crucial for various scientific and practical applications, including safe navigation in this challenging region.\n",
    "\n",
    "view 1: Sentinel-1 image\n",
    "\n",
    "<img alt=\"nersc_sar_primary view\" src=\"nersc_sar_primary.jpg\"/>\n",
    "\n",
    "view 2: AMSR2 image\n",
    "\n",
    "<img src=\"btemp_89_0h.jpg\" alt = \"btemp_89_0h view\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the data.zip file from Canvas, and then execute the cell below to import the data. You can customize the directory name for the data if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " shape view 1 data:  (13683, 32, 32)\n",
      " shape view 2 data:  (13683, 32, 32)\n",
      " shape labels data:  (13683, 1)\n"
     ]
    }
   ],
   "source": [
    "def load_data_from_directories(view1_dir, view2_dir, labels_dir):\n",
    "    \"\"\"\n",
    "    Load data from directories containing two views and corresponding labels.\n",
    "\n",
    "    Parameters:\n",
    "    - view1_dir (str): Path to the directory containing view 1 data files.\n",
    "    - view2_dir (str): Path to the directory containing view 2 data files.\n",
    "    - labels_dir (str): Path to the directory containing label data files.\n",
    "\n",
    "    Returns:\n",
    "    - view1_data (numpy.ndarray): NumPy array containing data from view 1.\n",
    "    - view2_data (numpy.ndarray): NumPy array containing data from view 2.\n",
    "    - labels_data (numpy.ndarray): NumPy array containing label data.\n",
    "\n",
    "    This function loads data from two views and their corresponding labels, assuming a common \"number\" part\n",
    "    in the file names for matching files. It ensures that data files from both views and labels are consistent\n",
    "    and loads them into NumPy arrays for further processing.\n",
    "    \"\"\"\n",
    "    # List all files in each directory\n",
    "    files_view1 = os.listdir(view1_dir)\n",
    "    files_view2 = os.listdir(view2_dir)\n",
    "    files_label = os.listdir(labels_dir)\n",
    "\n",
    "    # Initialize empty lists to store data from each view and labels\n",
    "    view1_data = []\n",
    "    view2_data = []\n",
    "    labels_data = []\n",
    "\n",
    "    # Iterate through the files in the directory\n",
    "    for filename in files_view1:\n",
    "        if filename.endswith('_samples_view1.npy'):\n",
    "            # Extract the common \"number\" part of the file name\n",
    "            common_number = filename.split('_')[0]\n",
    "\n",
    "            # Check if corresponding files exist for view2 and labels\n",
    "            if common_number + '_samples_view2.npy' in files_view2 and common_number + '_labels.npy' in files_label:\n",
    "                # Load data from the NumPy files\n",
    "                data_view1 = np.load(os.path.join(view1_dir, filename))\n",
    "                data_view2 = np.load(os.path.join(view2_dir, common_number + '_samples_view2.npy'))\n",
    "                data_labels = np.load(os.path.join(labels_dir, common_number + '_labels.npy'))\n",
    "\n",
    "                # Append data to respective lists\n",
    "                view1_data.append(data_view1)\n",
    "                view2_data.append(data_view2)\n",
    "                labels_data.append(data_labels)\n",
    "\n",
    "    view1_data = np.array(view1_data)\n",
    "    view2_data = np.array(view2_data)\n",
    "    labels_data = np.array(labels_data)\n",
    "\n",
    "    return view1_data, view2_data, labels_data\n",
    "\n",
    "\n",
    "view1_dir = 'C:/Users/srina/Documents/Big Data science/data/view1/' \n",
    "view2_dir = 'C:/Users/srina/Documents/Big Data science/data/view2/' \n",
    "labels_dir = 'C:/Users/srina/Documents/Big Data science/data/labels/' \n",
    "\n",
    "view1_data, view2_data, labels_data = load_data_from_directories(view1_dir, view2_dir, labels_dir)\n",
    "\n",
    "\n",
    "print(\" shape view 1 data: \", view1_data.shape)\n",
    "print(\" shape view 2 data: \", view2_data.shape)\n",
    "print(\" shape labels data: \", labels_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:20px;color:#F1F8FC;background-color:#0095EA;padding:10px;\">Part  1. Co-Training Models for Sea Ice Classification</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you'll be applying the Co-training technique to the dataset. Through this, you'll observe the outcomes of both semi-supervised learning and supervised learning when there's only a limited amount of labeled data available. You may want to revisit Lecture 02, which covers the topic of cotraining for a more comprehensive understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-1. Divide the dataset into three distinct sets: one for labeled data, one for unlabeled data, and one for test data. Make sure that the labeled dataset contains between 100 and 130 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Please write your code here. Comments are provided for guidance purposes. make adjustments as needed.\n",
    "\n",
    "labeled_set = {}\n",
    "unlabeled_set = {}\n",
    "test_set = {}\n",
    "\n",
    "def split_dataset(dataset_view1, dataset_view2, labeled_size=120, test_size=0.2, random_seed=42):\n",
    "    \"\"\"\n",
    "    Split the dataset into labeled, unlabeled, and test sets.\n",
    "\n",
    "    Parameters:\n",
    "    - dataset (list or array-like): The input dataset to be split.\n",
    "    - labeled_size (int): The target size for the labeled set (default: 130).\n",
    "    - test_size (float): The proportion of the dataset to include in the test split (default: 0.2).\n",
    "    - random_seed (int): Seed for reproducibility (default: None).\n",
    "\n",
    "    Returns:\n",
    "    - labeled_set_view1: Subset of the dataset with labeled data (approximately 100-130 points).\n",
    "    - labeled_set_view2: Subset of the dataset with labeled data (approximately 100-130 points).\n",
    "    - label_labeled_set: Labels corresponding to the labeled data points.\n",
    "    - unlabeled_set: Subset of the dataset with unlabeled data.\n",
    "    - test_set: Subset of the dataset for testing.\n",
    "    - label_test_set: Labels corresponding to the test data points.\n",
    "    \"\"\"\n",
    "    np.random.seed(random_seed)\n",
    "    n_samples = len(dataset_view1)\n",
    "    indices = np.random.permutation(n_samples)\n",
    "    \n",
    "    n_labeled = int(labeled_size)\n",
    "    n_test = int(n_samples * test_size)\n",
    "\n",
    "    end_labeled = n_labeled\n",
    "    start_test = end_labeled\n",
    "    end_test = start_test + n_test\n",
    "    \n",
    "    labeled_indices = indices[:end_labeled]\n",
    "    test_indices = indices[start_test:end_test]\n",
    "    unlabeled_indices = indices[end_test:]\n",
    "\n",
    "    datasets = {\n",
    "        \"view1\": dataset_view1,\n",
    "        \"view2\": dataset_view2,\n",
    "        \"labels\": labels_data  \n",
    "    }\n",
    "\n",
    "    def extract(subset_indices):\n",
    "        return {key: value[subset_indices] for key, value in datasets.items()}\n",
    "\n",
    "    labeled_set = extract(labeled_indices)\n",
    "    test_set = extract(test_indices)\n",
    "    unlabeled_set = {key: value[unlabeled_indices] for key, value in datasets.items()}\n",
    "    \n",
    "    labeled_set_view1 = labeled_set[\"view1\"]\n",
    "    labeled_set_view2 = labeled_set[\"view2\"]\n",
    "    label_labeled_set = labeled_set[\"labels\"]\n",
    "    label_test_set = test_set[\"labels\"]\n",
    "\n",
    "    return (\n",
    "        labeled_set_view1, labeled_set_view2, label_labeled_set,\n",
    "        unlabeled_set,\n",
    "        test_set, test_set[\"labels\"]\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-2. initialize two classifiers for each view using scikit-learn. Consider using a Convolutional Neural Network (CNN) as one of the classifiers and a Random Forest as the other.\n",
    "Here's a short description of the configuration for the CNN (Convolutional Neural Network) and Random Forest (RF) classifiers to implement:\n",
    "\n",
    "**CNN Classifier Configuration:**\n",
    "\n",
    "1. Input Layer: BatchNormalization with input shape (32, 32, 1).\n",
    "2. Convolutional Layer 1: 32 filters, each with a 3x3 kernel and ReLU activation.\n",
    "3. Max Pooling Layer 1: 2x2 pooling with a stride of 2.\n",
    "4. Convolutional Layer 2: 32 filters, each with a 3x3 kernel and ReLU activation.\n",
    "5. Max Pooling Layer 2: 2x2 pooling with a stride of 2.\n",
    "6. Convolutional Layer 3: 32 filters, each with a 3x3 kernel and ReLU activation.\n",
    "7. Max Pooling Layer 3: 2x2 pooling with a stride of 2.\n",
    "8. BatchNormalization Layer.\n",
    "9. Flatten Layer.\n",
    "10. Dropout Layer with a dropout rate of 0.1.\n",
    "11. Fully Connected Layer 1: 16 neurons, ReLU activation, and L2 regularization with a weight decay of 0.001.\n",
    "12. Dropout Layer with a dropout rate of 0.1.\n",
    "13. Fully Connected Layer 2: 16 neurons, ReLU activation, and L2 regularization with a weight decay of 0.001.\n",
    "14. Dropout Layer with a dropout rate of 0.1.\n",
    "15. Output Layer: Dense layer with the number of neurons equal to the number of classes and softmax activation.\n",
    "\n",
    "**CNN Model Compilation:**\n",
    "- Optimizer: Adam\n",
    "- Loss Function: Sparse Categorical Crossentropy\n",
    "- Metrics for Evaluation: Accuracy\n",
    "\n",
    "**Random Forest Classifier Configuration:**\n",
    "- Number of Estimators: 20\n",
    "- Random State: 42\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 6\n",
    "# write your code here\n",
    "#implement classifiers based on the provided definition\n",
    "#cnn_classifier =\n",
    "#rf_classifier =\n",
    "\n",
    "def create_cnn_classifier(num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization(input_shape=(32, 32, 1)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=2))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=2))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(16, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(16, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_rf_classifier(num_estimators, random_state):\n",
    "    rf_clf = RandomForestClassifier(n_estimators=num_estimators, random_state=random_state)\n",
    "    return rf_clf\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-3. Do the co-training part:\n",
    "   - Train classifiers on the labeled data\n",
    "   - Predict on the unlabeled data and identify instances that have a confidence score more than 90.\n",
    "   - Add the confident instances to the labeled set and train again\n",
    "   - Compute the accuracy of the classifiers on test set\n",
    "To provide a more understanding of the accuracy measure, please refer to the following link: [link](https://en.wikipedia.org/wiki/Accuracy_and_precision).\n",
    "<img src=\"accuracy.jpg\" alt = \"accuracy metric\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    " # Please write your code here. Comments are provided for guidance purposes. make adjustments as needed.\n",
    "def co_training(classifier1, classifier2, labeled_set, unlabeled_set, test_set , threshold_confidence):\n",
    "    \"\"\"\n",
    "    Perform co-training with two classifiers on labeled and unlabeled data.\n",
    "\n",
    "    Parameters:\n",
    "    - classifier1: The first classifier (e.g., CNN).\n",
    "    - classifier2: The second classifier (e.g., Random Forest).\n",
    "    - labeled_set (list or array-like): Labeled dataset.\n",
    "    - unlabeled_set (list or array-like): Unlabeled dataset.\n",
    "    - test_set (list or array-like): Test dataset.\n",
    "    - threshold_confidence (float): The minimum confidence threshold for adding unlabeled samples to the training set.\n",
    "\n",
    "    Returns:\n",
    "    - classifier1_accuracy (float): Accuracy of Classifier 1 on the test set after co-training.\n",
    "    - classifier2_accuracy (float): Accuracy of Classifier 2 on the test set after co-training.\n",
    "    \"\"\"\n",
    "    samples_1, x1, y1 = labeled_set[\"view2\"].shape\n",
    "    labeled_set_2_2D = labeled_set[\"view2\"].reshape((samples_1,x1*y1))\n",
    "    \n",
    "    samples_2, x2, y2 = unlabeled_set[\"view2\"].shape\n",
    "    unlabeled_set_2_2D = unlabeled_set[\"view2\"].reshape((samples_2,x2*y2))\n",
    "    \n",
    "    samples_3, x3, y3 = test_set[\"view2\"].shape\n",
    "    test_set_2_2D = test_set[\"view2\"].reshape((samples_3,x3*y3))\n",
    "    \n",
    "    classifier1.fit(labeled_set[\"view1\"], labeled_set[\"labels\"])\n",
    "    classifier2.fit(labeled_set_2_2D, labeled_set[\"labels\"])\n",
    "\n",
    "    predictions1 = classifier1.predict(unlabeled_set[\"view1\"])\n",
    "    predictions2 = classifier2.predict(unlabeled_set_2_2D)\n",
    "\n",
    "    confidences1 = np.max(classifier1.predict(unlabeled_set[\"view1\"]), axis=1)\n",
    "    confidences2 = np.max(classifier2.predict_proba(unlabeled_set_2_2D), axis=1)\n",
    "\n",
    "    confident_samples_1 = np.where(confidences1 > threshold_confidence)[0]\n",
    "    confident_samples_2 = np.where(confidences2 > threshold_confidence)[0]\n",
    "\n",
    "    unlabeled_set_1_temp = unlabeled_set[\"view1\"]\n",
    "    updated_labeled_set_1 = np.vstack((labeled_set[\"view1\"], unlabeled_set_1_temp[confident_samples_1]))\n",
    "    updated_label_labeled_set_1 = np.append(labeled_set[\"labels\"], predictions1[confident_samples_1])\n",
    "        \n",
    "    updated_labeled_set_2_2D = np.vstack((labeled_set_2_2D, unlabeled_set_2_2D[confident_samples_2]))\n",
    "    updated_label_labeled_set_2 = np.append(labeled_set[\"labels\"], predictions2[confident_samples_2])\n",
    "\n",
    "    classifier1.fit(updated_labeled_set_1, updated_label_labeled_set_1)\n",
    "    classifier2.fit(updated_labeled_set_2_2D, updated_label_labeled_set_2)\n",
    "\n",
    "    # Compute accuracy on the test set\n",
    "    classifier1_accuracy = classifier1.evaluate(test_set[\"view1\"], test_set[\"labels\"])\n",
    "    classifier2_accuracy = classifier2.score(test_set_2_2D, test_set[\"labels\"])\n",
    "\n",
    "    return classifier1_accuracy, classifier2_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-4. pick one of the classifiers and do the supervised training with the labeled data and calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Please write your code here. Comments are provided for guidance purposes. make adjustments as needed.\n",
    "def supervised_training_and_accuracy(classifier, labeled_data, labeled_labels, test_data, test_labels):\n",
    "    \"\"\"\n",
    "    Perform supervised training with a classifier on the labeled data and calculate the accuracy on test data.\n",
    "\n",
    "    Parameters:\n",
    "    - classifier: The classifier to be used for supervised training (e.g., Random Forest).\n",
    "    - labeled_data (array-like): Labeled training data.\n",
    "    - labeled_labels (array-like): Labels for the labeled training data.\n",
    "    - test_data (array-like): Test data for evaluation.\n",
    "    - test_labels (array-like): Labels for the test data.\n",
    "\n",
    "    Returns:\n",
    "    - accuracy (float): Accuracy of the classifier on the test data after supervised training.\n",
    "    \"\"\"\n",
    "    samples_1, x1, y1 = labeled_data.shape\n",
    "    labeled_set_2_2D = labeled_data.reshape((samples_1,x1*y1))\n",
    "    \n",
    "    samples_3, x3, y3 = test_data.shape\n",
    "    test_set_2_2D = test_data.reshape((samples_3,x3*y3))\n",
    "    \n",
    "    classifier.fit(labeled_set_2_2D, labeled_labels)\n",
    "    accuracy = classifier.score(test_set_2_2D, test_labels)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-5. Compare the Co-training approach accuracy and supervised model with limited labeled data and write your reason about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 12ms/step - loss: 1.7883 - accuracy: 0.2667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srina\\AppData\\Local\\Temp\\ipykernel_17148\\3760836582.py:28: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  classifier2.fit(labeled_set_2_2D, labeled_set[\"labels\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 2s 6ms/step\n",
      "339/339 [==============================] - 5s 15ms/step\n",
      "4/4 [==============================] - 1s 20ms/step - loss: 1.3985 - accuracy: 0.5083\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 1.7494 - accuracy: 0.6166\n",
      "Co-training CNN Accuracy: [1.7494062185287476, 0.6165935397148132]\n",
      "Co-training Random Forest Accuracy: 0.893640350877193\n",
      "Supervised Random Forest Accuracy: 0.8636695906432749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srina\\AppData\\Local\\Temp\\ipykernel_17148\\1336973450.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  classifier.fit(labeled_set_2_2D, labeled_labels)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n Answer \\n Here we are comparing the co-training and supervised learning approaches. When see result you can clearly say that \\n co-training method produces better results than supervised. In co-training we are using both CNN and Random forest for different views of data.\\n while in supervised we are considereing random forest. If you only compare the random forest accaurcies only, random forest in co-training gives better results \\n because unlabeled data is also used in training of co-training approach.\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code and answer here\n",
    "labeled_set[\"view1\"], labeled_set[\"view2\"], labeled_set[\"labels\"], unlabeled_set, test_set, test_set[\"labels\"] = split_dataset(view1_data, view2_data, labeled_size= 120)\n",
    "\n",
    "cnn_classifier = create_cnn_classifier(num_classes)\n",
    "\n",
    "rf_classifier = create_rf_classifier(num_estimators=20, random_state=42)\n",
    "\n",
    "cnn_accuracy, rf_accuracy = co_training(cnn_classifier , rf_classifier, \n",
    "                                        labeled_set,\n",
    "                                        unlabeled_set,\n",
    "                                        test_set,\n",
    "                                        threshold_confidence= 0.90)\n",
    "\n",
    "rf_supervised_accuracy = supervised_training_and_accuracy(rf_classifier, labeled_set[\"view2\"], labeled_set[\"labels\"], test_set[\"view2\"], test_set[\"labels\"])\n",
    "\n",
    "print(f\"Co-training CNN Accuracy: {cnn_accuracy}\")\n",
    "print(f\"Co-training Random Forest Accuracy: {rf_accuracy}\")\n",
    "print(f\"Supervised Random Forest Accuracy: {rf_supervised_accuracy}\")\n",
    "\n",
    "\"\"\"\n",
    " Answer \n",
    " Here we are comparing the co-training and supervised learning approaches. When see result you can clearly say that \n",
    " co-training method produces better results than supervised. In co-training we are using both CNN and Random forest for different views of data.\n",
    " while in supervised we are considereing random forest. If you only compare the random forest accaurcies only, random forest in co-training gives better results \n",
    " because unlabeled data is also used in training of co-training approach.\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:20px;color:#F1F8FC;background-color:#0095EA;padding:10px;\">Part 2. Label Propagation for Sea Ice Classification</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you'll be applying the label propagation technique to the dataset. Through this, you'll observe the outcomes of both semi-supervised learning and supervised learning when there's only a limited amount of labeled data available.\n",
    "\n",
    "\n",
    "<img src=\"label_propagation.jpg\" alt = \"label propgation process\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 2-1. Apply the K-Nearest Neighbors (KNN) algorithm with a parameter configuration where n_neighbors is set to 7 for the label propagation model. Utilize one of the labeled data views and the corresponding unlabeled data from part 1 as input.\n",
    "To provide a more understanding of the accuracy measure, please refer to the following link: [link](https://en.wikipedia.org/wiki/Accuracy_and_precision)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srina\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy for label propogation: 0.8088450292397661\n"
     ]
    }
   ],
   "source": [
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Please write your code here. Comments are provided for guidance purposes. make adjustments as needed.\n",
    "def label_propagation(labeled_data, unlabeled_data, labeled_labels, test_data, label_test, n_neighbors=7):\n",
    "    \"\"\"\n",
    "    Apply K-Nearest Neighbors (KNN) to the label propagation model on one data view and test data.\n",
    "\n",
    "    Parameters:\n",
    "    - labeled_data (array-like): Labeled data points.\n",
    "    - unlabeled_data (array-like): Unlabeled data points.\n",
    "    - labeled_labels (array-like): Labels corresponding to the labeled data points.\n",
    "    - test_data (array-like): Test data to evaluate label propagation performance.\n",
    "    - label_test (array-like): Labels corresponding to the test data points.\n",
    "    - n_neighbors (int): Number of neighbors to consider in KNN (default: 7).\n",
    "\n",
    "    Returns:\n",
    "    - accuracy (float): Accuracy of label propagation on the test data.\n",
    "    \"\"\"\n",
    "    samples_1, x1, y1 = labeled_data.shape\n",
    "    labeled_set_1_2D = labeled_data.reshape((samples_1,x1*y1))\n",
    "    \n",
    "    samples_2, x2, y2 = unlabeled_data.shape\n",
    "    unlabeled_set_1_2D = unlabeled_data.reshape((samples_2,x2*y2))\n",
    "    \n",
    "    samples_3, x3, y3 = test_data.shape\n",
    "    test_set_1_2D = test_data.reshape((samples_3,x3*y3))\n",
    "    \n",
    "    label_prop_model = LabelPropagation(kernel=\"knn\", n_neighbors=n_neighbors, max_iter=1000)\n",
    "    \n",
    "    label_prop_model.fit(labeled_set_1_2D, labeled_labels)\n",
    "    \n",
    "    predicted_labels = label_prop_model.predict(unlabeled_set_1_2D)\n",
    "    \n",
    "    data_combined = np.vstack([labeled_set_1_2D, unlabeled_set_1_2D])\n",
    "    \n",
    "    all_labels = np.concatenate([labeled_labels.flatten(), predicted_labels])\n",
    "    \n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "\n",
    "    knn_classifier.fit(data_combined, all_labels)\n",
    "\n",
    "    test_predicted_labels = knn_classifier.predict(test_set_1_2D)\n",
    "    \n",
    "    accuracy = accuracy_score(label_test, test_predicted_labels)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "label_prop_accuracy = label_propagation(labeled_set[\"view1\"], unlabeled_set[\"view1\"], labeled_set[\"labels\"], test_set[\"view1\"], test_set[\"labels\"], n_neighbors=7)\n",
    "\n",
    "print(f\"KNN Accuracy for label propogation: {label_prop_accuracy}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-2. Select a classification algorithm and perform supervised learning on the labeled set. Then, evaluate the model's performance by calculating the accuracy. You can use a built-in library for the classifier. Compare your sepervised and semi supervised accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supervised training accuracy: 0.8636695906432749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srina\\AppData\\Local\\Temp\\ipykernel_17148\\1439951563.py:23: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  classifier.fit(labeled_set_1_2D, labeled_labels)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nAnswer: \\nWhen you see the accuraices of both semi-supervised and supervised learning approaches. Supervised learning gives better result \\nbecause the whole dataset which is considered for training the model is labeled, while in semi-supervised, you model is predicting the \\nunlabeled data as well. With all considered, the accuracy of semi-supervised is near to the supervised which is comsidered remarkable \\nbecause it saves you all the time labelling data and more data to train your model.\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Please write your code here. Comments are provided for guidance purposes. make adjustments as needed.\n",
    "def supervised_training_and_accuracy(classifier, labeled_data, labeled_labels, test_data, test_labels):\n",
    "    \"\"\"\n",
    "    Perform supervised training with a classifier on the labeled data and calculate the accuracy on test data.\n",
    "\n",
    "    Parameters:\n",
    "    - classifier: The classifier to be used for supervised training (e.g., Random Forest).\n",
    "    - labeled_data (array-like): Labeled training data.\n",
    "    - labeled_labels (array-like): Labels for the labeled training data.\n",
    "    - test_data (array-like): Test data for evaluation.\n",
    "    - test_labels (array-like): Labels for the test data.\n",
    "\n",
    "    Returns:\n",
    "    - accuracy (float): Accuracy of the classifier on the test data after supervised training.\n",
    "    \"\"\"\n",
    "    \n",
    "    samples_1, x1, y1 = labeled_data.shape\n",
    "    labeled_set_1_2D = labeled_data.reshape((samples_1,x1*y1))\n",
    "    \n",
    "    samples_2, x2, y2 = test_data.shape\n",
    "    test_data_1_2D = test_data.reshape((samples_2,x2*y2))\n",
    "    \n",
    "    classifier.fit(labeled_set_1_2D, labeled_labels)\n",
    "    \n",
    "    predictions = classifier.predict(test_data_1_2D)\n",
    "    \n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "rnd_f_accuracy = supervised_training_and_accuracy(rf_classifier, labeled_set[\"view1\"], labeled_set[\"labels\"], test_set[\"view1\"], test_set[\"labels\"])\n",
    "\n",
    "print(f\"Supervised training accuracy: {rnd_f_accuracy}\")\n",
    "\n",
    "\"\"\"\n",
    "Answer: \n",
    "When you see the accuraices of both semi-supervised and supervised learning approaches. Supervised learning gives better result \n",
    "because the whole dataset which is considered for training the model is labeled, while in semi-supervised, you model is predicting the \n",
    "unlabeled data as well. With all considered, the accuracy of semi-supervised is near to the supervised which is comsidered remarkable \n",
    "because it saves you all the time labelling data and more data to train your model.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:20px;color:#F1F8FC;background-color:#0095EA;padding:10px;\">Part 3. Now let's perform some experimentation and make some observations!</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-1. We will explore the impact of varying the threshold confidence in the co-training process at three different values: 80, 70, and 60. We will then assess the accuracy of co-training based on these threshold settings.\n",
    "To provide a more understanding of the accuracy measure, please refer to the following link: [link](https://en.wikipedia.org/wiki/Accuracy_and_precision)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 44ms/step - loss: 1.2950 - accuracy: 0.6333\n",
      "  1/339 [..............................] - ETA: 11s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srina\\AppData\\Local\\Temp\\ipykernel_17148\\3760836582.py:28: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  classifier2.fit(labeled_set_2_2D, labeled_set[\"labels\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 4s 11ms/step\n",
      "339/339 [==============================] - 3s 10ms/step\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.1824 - accuracy: 0.6417\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 1.7308 - accuracy: 0.6166\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0980 - accuracy: 0.6750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srina\\AppData\\Local\\Temp\\ipykernel_17148\\3760836582.py:28: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  classifier2.fit(labeled_set_2_2D, labeled_set[\"labels\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 4s 11ms/step\n",
      "339/339 [==============================] - 4s 11ms/step\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.0614 - accuracy: 0.6583\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 1.6943 - accuracy: 0.6166\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.9425 - accuracy: 0.6750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srina\\AppData\\Local\\Temp\\ipykernel_17148\\3760836582.py:28: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  classifier2.fit(labeled_set_2_2D, labeled_set[\"labels\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 4s 11ms/step\n",
      "339/339 [==============================] - 4s 11ms/step\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.9632 - accuracy: 0.6833\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 1.6921 - accuracy: 0.6166\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "labeled_set[\"view1\"], labeled_set[\"view2\"], labeled_set[\"labels\"], unlabeled_set, test_set, test_set[\"labels\"] = split_dataset(view1_data, view2_data, labeled_size= 120)\n",
    "\n",
    "cnn_accuracy_1, rf_accuracy_1 = co_training(cnn_classifier , rf_classifier, \n",
    "                                        labeled_set,\n",
    "                                        unlabeled_set,\n",
    "                                        test_set,\n",
    "                                        threshold_confidence= 0.80)\n",
    "\n",
    "labeled_set[\"view1\"], labeled_set[\"view2\"], labeled_set[\"labels\"], unlabeled_set, test_set, test_set[\"labels\"] = split_dataset(view1_data, view2_data, labeled_size= 120)\n",
    "\n",
    "\n",
    "cnn_accuracy_2, rf_accuracy_2 = co_training(cnn_classifier , rf_classifier, \n",
    "                                        labeled_set,\n",
    "                                        unlabeled_set,\n",
    "                                        test_set,\n",
    "                                        threshold_confidence= 0.70)\n",
    "\n",
    "labeled_set[\"view1\"], labeled_set[\"view2\"], labeled_set[\"labels\"], unlabeled_set, test_set, test_set[\"labels\"] = split_dataset(view1_data, view2_data, labeled_size= 120)\n",
    "\n",
    "\n",
    "cnn_accuracy_3, rf_accuracy_3 = co_training(cnn_classifier , rf_classifier, \n",
    "                                        labeled_set,\n",
    "                                        unlabeled_set,\n",
    "                                        test_set,\n",
    "                                        threshold_confidence= 0.60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Co-training of CNN Accuracy: [1.73076593875885, 0.6165935397148132] and Random Forest Accuracy: 0.893640350877193\n",
      "Co-training of CNN Accuracy: [1.6942936182022095, 0.6165935397148132] and Random Forest Accuracy: 0.893640350877193\n",
      "Co-training of CNN Accuracy: [1.6920809745788574, 0.6165935397148132] and Random Forest Accuracy: 0.893640350877193\n"
     ]
    }
   ],
   "source": [
    "print(f\"Co-training of CNN Accuracy: {cnn_accuracy_1} and Random Forest Accuracy: {rf_accuracy_1}\")\n",
    "print(f\"Co-training of CNN Accuracy: {cnn_accuracy_2} and Random Forest Accuracy: {rf_accuracy_2}\")\n",
    "print(f\"Co-training of CNN Accuracy: {cnn_accuracy_3} and Random Forest Accuracy: {rf_accuracy_3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-2. Change the parameters of the K-Nearest Neighbors (KNN) algorithm for Label Propagation (part 2) with the values 3, 5, and 10, and explain what you understand about these parameter adjustments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srina\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\srina\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\srina\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy for label propogation for 3: 0.8212719298245614\n",
      "KNN Accuracy for label propogation for 5: 0.8212719298245614\n",
      "KNN Accuracy for label propogation for 10: 0.8088450292397661\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nAnswer:\\nWhen you see the outputs for different value of K's, as the K value increases the accuracy of the model is decreasing this \\nis because as k value increase it is more overfitting and less bias towards the outliers. But when the K values is low and \\nvalues are near it does have negligible effect on accauray has you can see in 2 and 5.\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "label_prop_accuracy_1 = label_propagation(labeled_set[\"view1\"], unlabeled_set[\"view1\"], labeled_set[\"labels\"], test_set[\"view1\"], test_set[\"labels\"], n_neighbors=3)\n",
    "label_prop_accuracy_2 = label_propagation(labeled_set[\"view1\"], unlabeled_set[\"view1\"], labeled_set[\"labels\"], test_set[\"view1\"], test_set[\"labels\"], n_neighbors=5)\n",
    "label_prop_accuracy_3 = label_propagation(labeled_set[\"view1\"], unlabeled_set[\"view1\"], labeled_set[\"labels\"], test_set[\"view1\"], test_set[\"labels\"], n_neighbors=10)\n",
    "\n",
    "\n",
    "print(f\"KNN Accuracy for label propogation for 3: {label_prop_accuracy_1}\")\n",
    "print(f\"KNN Accuracy for label propogation for 5: {label_prop_accuracy_2}\")\n",
    "print(f\"KNN Accuracy for label propogation for 10: {label_prop_accuracy_3}\")\n",
    "\n",
    "\"\"\"\n",
    "Answer:\n",
    "When you see the outputs for different value of K's, as the K value increases the accuracy of the model is decreasing this \n",
    "is because as k value increase it is more overfitting and less bias towards the outliers. But when the K values is low and \n",
    "values are near it does have negligible effect on accauray has you can see in 2 and 5.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "3-3. Let's see the impact of of a simplifies models for cotraining approach.\n",
    "- Reduce the number of convolutional layers in the question 1-2 from 3 to 1 convolution layer and the rest of the layers is the same\n",
    "- Change the number of trees for the random forest algorithm to 1.\n",
    "Evaluate the performance of cotraining approach.\n",
    "- Additionally, use the 1 layer convolution layer as the supervised model and evaluate the performance for supervised learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 21ms/step - loss: 3.4209 - accuracy: 0.1333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srina\\AppData\\Local\\Temp\\ipykernel_17148\\3760836582.py:28: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  classifier2.fit(labeled_set_2_2D, labeled_set[\"labels\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 2s 7ms/step\n",
      "339/339 [==============================] - 2s 7ms/step\n",
      "4/4 [==============================] - 1s 21ms/step - loss: 1.7620 - accuracy: 0.5417\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 1.7227 - accuracy: 0.3706\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 2.6863 - accuracy: 0.4333\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 1.4787 - accuracy: 0.5863\n",
      "Co-training CNN Accuracy: [1.722702980041504, 0.37061402201652527]\n",
      "Co-training Random Forest Accuracy: 0.8154239766081871\n",
      "Supervised Random Forest Accuracy: [1.4786882400512695, 0.5862573385238647]\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "def modified_cnn_classifier(num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization(input_shape=(32, 32, 1)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(16, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(16, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def modified_rf_classifier(num_estimators, random_state):\n",
    "    rf_clf = RandomForestClassifier(n_estimators=num_estimators, random_state=random_state)\n",
    "    return rf_clf\n",
    "\n",
    "def modified_supervised_training_and_accuracy(classifier, labeled_data, labeled_labels, test_data, test_labels):\n",
    "    classifier.fit(labeled_data, labeled_labels)\n",
    "    accuracy = classifier.evaluate(test_data, test_labels)\n",
    "    return accuracy\n",
    "\n",
    "cnn_classifier_1 = modified_cnn_classifier(num_classes =6)\n",
    "\n",
    "rf_classifier_1 = modified_rf_classifier(num_estimators=1, random_state=42)\n",
    "\n",
    "# Co-training\n",
    "cnn_accuracy_4, rf_accuracy_4 = co_training(cnn_classifier_1 , rf_classifier_1, \n",
    "                                        labeled_set,\n",
    "                                        unlabeled_set,\n",
    "                                        test_set,\n",
    "                                        threshold_confidence= 0.90)\n",
    "\n",
    "# Supervised training with one of the classifiers (e.g., Random Forest)\n",
    "cnn_supervised_accuracy = modified_supervised_training_and_accuracy(cnn_classifier_1, labeled_set[\"view2\"], labeled_set[\"labels\"], test_set[\"view2\"], test_set[\"labels\"])\n",
    "\n",
    "# Compare accuracies\n",
    "print(f\"Co-training CNN Accuracy: {cnn_accuracy_4}\")\n",
    "print(f\"Co-training Random Forest Accuracy: {rf_accuracy_4}\")\n",
    "print(f\"Supervised Random Forest Accuracy: {cnn_supervised_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-4. Let's adjust the amount of labeled data in part 2 by considering two different quantities: 200 and 400 labeled data points. In each scenario, the remaining data will remain unlabeled. Evaluate the performance of label propagation under these labeled data scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srina\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\srina\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy for label propogation for labeled size of 200: 0.8870614035087719\n",
      "KNN Accuracy for label propogation for labeled size of 400: 0.8863304093567251\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "labeled_set[\"view1\"], labeled_set[\"view2\"], labeled_set[\"labels\"], unlabeled_set, test_set, test_set[\"labels\"] = split_dataset(view1_data, view2_data, labeled_size= 200)\n",
    "label_prop_accuracy2 = label_propagation(labeled_set[\"view1\"], unlabeled_set[\"view1\"], labeled_set[\"labels\"], test_set[\"view1\"], test_set[\"labels\"], n_neighbors=7)\n",
    "\n",
    "labeled_set[\"view1\"], labeled_set[\"view2\"], labeled_set[\"labels\"], unlabeled_set, test_set, test_set[\"labels\"] = split_dataset(view1_data, view2_data, labeled_size= 400)\n",
    "label_prop_accuracy3 = label_propagation(labeled_set[\"view1\"], unlabeled_set[\"view1\"], labeled_set[\"labels\"], test_set[\"view1\"], test_set[\"labels\"], n_neighbors=7)\n",
    "\n",
    "print(f\"KNN Accuracy for label propogation for labeled size of 200: {label_prop_accuracy2}\")\n",
    "print(f\"KNN Accuracy for label propogation for labeled size of 400: {label_prop_accuracy3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3-5. Let's adjust the number of labeled data samples for part 1. Consider three scenarios: one with 200 labeled samples, another with 400 labeled samples, and a third with 600 labeled samples. In each scenario, the remaining data will remain unlabeled. Additionally, include an explanation of your understanding of how these parameter changes impact the algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 24ms/step - loss: 1.4837 - accuracy: 0.6150\n",
      "  9/336 [..............................] - ETA: 2s "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srina\\AppData\\Local\\Temp\\ipykernel_17148\\3760836582.py:28: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  classifier2.fit(labeled_set_2_2D, labeled_set[\"labels\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336/336 [==============================] - 2s 6ms/step\n",
      "336/336 [==============================] - 2s 7ms/step\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 1.2592 - accuracy: 0.6350\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 1.4389 - accuracy: 0.8399\n",
      "Co-training CNN Accuracy for 200 labeled: [1.4388943910598755, 0.8399122953414917]\n",
      "Co-training Random Forest Accuracy for 200 labeled: 0.8870614035087719\n",
      "Supervised Random Forest Accuracy for 200 labeled: 0.8929093567251462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srina\\AppData\\Local\\Temp\\ipykernel_17148\\1439951563.py:23: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  classifier.fit(labeled_set_1_2D, labeled_labels)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 20ms/step - loss: 0.8101 - accuracy: 0.7525\n",
      "  1/330 [..............................] - ETA: 10s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srina\\AppData\\Local\\Temp\\ipykernel_17148\\3760836582.py:28: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  classifier2.fit(labeled_set_2_2D, labeled_set[\"labels\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330/330 [==============================] - 2s 6ms/step\n",
      "330/330 [==============================] - 2s 7ms/step\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 0.7851 - accuracy: 0.7500\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 1.3612 - accuracy: 0.8735\n",
      "Co-training CNN Accuracy for 400 labeled: [1.3612128496170044, 0.8735380172729492]\n",
      "Co-training Random Forest Accuracy for 400 labeled: 0.8793859649122807\n",
      "Supervised Random Forest Accuracy for 400 labeled: 0.8881578947368421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srina\\AppData\\Local\\Temp\\ipykernel_17148\\1439951563.py:23: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  classifier.fit(labeled_set_1_2D, labeled_labels)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 22ms/step - loss: 0.7442 - accuracy: 0.7383\n",
      "  1/324 [..............................] - ETA: 10s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srina\\AppData\\Local\\Temp\\ipykernel_17148\\3760836582.py:28: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  classifier2.fit(labeled_set_2_2D, labeled_set[\"labels\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 2s 7ms/step\n",
      "324/324 [==============================] - 2s 6ms/step\n",
      "19/19 [==============================] - 0s 22ms/step - loss: 0.7043 - accuracy: 0.7650\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 1.2422 - accuracy: 0.8052\n",
      "Co-training CNN Accuracy for 600 labeled: [1.242202877998352, 0.8051900863647461]\n",
      "Co-training Random Forest Accuracy for 600 labeled: 0.8914473684210527\n",
      "Supervised Random Forest Accuracy for 600 labeled: 0.8914473684210527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srina\\AppData\\Local\\Temp\\ipykernel_17148\\1439951563.py:23: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  classifier.fit(labeled_set_1_2D, labeled_labels)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nAnswer:\\nAs the size of the labeled data is increased the accuracy of both co-training and supervised learning accuracies are increasing which is expected because \\nyou are providing more accurate data to train your model.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_set[\"view1\"], labeled_set[\"view2\"], labeled_set[\"labels\"], unlabeled_set, test_set, test_set[\"labels\"] = split_dataset(view1_data, view2_data, labeled_size = 200)\n",
    "cnn_acc, rf_acc = co_training(cnn_classifier_1 , rf_classifier_1, \n",
    "                                        labeled_set,\n",
    "                                        unlabeled_set,\n",
    "                                        test_set,\n",
    "                                        threshold_confidence= 0.90)\n",
    "\n",
    "rf_supervised_accu = supervised_training_and_accuracy(rf_classifier, labeled_set[\"view2\"], labeled_set[\"labels\"], test_set[\"view2\"], test_set[\"labels\"])\n",
    "\n",
    "print(f\"Co-training CNN Accuracy for 200 labeled: {cnn_acc}\")\n",
    "print(f\"Co-training Random Forest Accuracy for 200 labeled: {rf_acc}\")\n",
    "print(f\"Supervised Random Forest Accuracy for 200 labeled: {rf_supervised_accu}\")\n",
    "\n",
    "labeled_set[\"view1\"], labeled_set[\"view2\"], labeled_set[\"labels\"], unlabeled_set, test_set, test_set[\"labels\"] = split_dataset(view1_data, view2_data, labeled_size = 400)\n",
    "cnn_acc, rf_acc = co_training(cnn_classifier_1 , rf_classifier_1, \n",
    "                                        labeled_set,\n",
    "                                        unlabeled_set,\n",
    "                                        test_set,\n",
    "                                        threshold_confidence= 0.90)\n",
    "\n",
    "rf_supervised_accu = supervised_training_and_accuracy(rf_classifier, labeled_set[\"view2\"], labeled_set[\"labels\"], test_set[\"view2\"], test_set[\"labels\"])\n",
    "\n",
    "print(f\"Co-training CNN Accuracy for 400 labeled: {cnn_acc}\")\n",
    "print(f\"Co-training Random Forest Accuracy for 400 labeled: {rf_acc}\")\n",
    "print(f\"Supervised Random Forest Accuracy for 400 labeled: {rf_supervised_accu}\")\n",
    "\n",
    "labeled_set[\"view1\"], labeled_set[\"view2\"], labeled_set[\"labels\"], unlabeled_set, test_set, test_set[\"labels\"] = split_dataset(view1_data, view2_data, labeled_size = 600)\n",
    "\n",
    "cnn_acc, rf_acc = co_training(cnn_classifier_1 , rf_classifier_1, \n",
    "                                        labeled_set,\n",
    "                                        unlabeled_set,\n",
    "                                        test_set,\n",
    "                                        threshold_confidence= 0.90)\n",
    "\n",
    "rf_supervised_accu = supervised_training_and_accuracy(rf_classifier, labeled_set[\"view2\"], labeled_set[\"labels\"], test_set[\"view2\"], test_set[\"labels\"])\n",
    "\n",
    "print(f\"Co-training CNN Accuracy for 600 labeled: {cnn_acc}\")\n",
    "print(f\"Co-training Random Forest Accuracy for 600 labeled: {rf_acc}\")\n",
    "print(f\"Supervised Random Forest Accuracy for 600 labeled: {rf_supervised_accu}\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Answer:\n",
    "As the size of the labeled data is increased the accuracy of both co-training and supervised learning accuracies are increasing which is expected because \n",
    "you are providing more accurate data to train your model.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3-6. Evalute the perfomance for different number of unlabeled data size.\n",
    "- Set labeled data size within the range of 100 to 130 and\n",
    "- Set the unlabeled data sizes at 200, 400, and 600.\n",
    "- Execute the algorithms and provide accuracy reports for both approaches: co-training and label propagation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "# Please write your code here. Comments are provided for guidance purposes. make adjustments as needed.\n",
    "\n",
    "labeled_set = {}\n",
    "unlabeled_set = {}\n",
    "test_set = {}\n",
    "\n",
    "def modified_split_dataset(dataset_view1, dataset_view2, unlabeled_size, labeled_size=120,  random_seed=42):\n",
    "\n",
    "    np.random.seed(random_seed)\n",
    "    n_samples = len(dataset_view1)\n",
    "    indices = np.random.permutation(n_samples)\n",
    "    \n",
    "    n_labeled = int(labeled_size)\n",
    "    n_unlabeled = int(unlabeled_size)\n",
    "\n",
    "    end_labeled = n_labeled\n",
    "    start_unlabeled = end_labeled\n",
    "    end_unlabeled = end_labeled + n_unlabeled\n",
    "    \n",
    "    labeled_indices = indices[:end_labeled]\n",
    "    unlabeled_indices = indices[start_unlabeled:end_unlabeled]\n",
    "    test_indices = indices[end_unlabeled:]\n",
    "\n",
    "    datasets = {\n",
    "        \"view1\": dataset_view1,\n",
    "        \"view2\": dataset_view2,\n",
    "        \"labels\": labels_data  \n",
    "    }\n",
    "\n",
    "    def extract(subset_indices):\n",
    "        return {key: value[subset_indices] for key, value in datasets.items()}\n",
    "\n",
    "    labeled_set = extract(labeled_indices)\n",
    "    test_set = extract(test_indices)\n",
    "    unlabeled_set = {key: value[unlabeled_indices] for key, value in datasets.items()}\n",
    "    \n",
    "    labeled_set_view1 = labeled_set[\"view1\"]\n",
    "    labeled_set_view2 = labeled_set[\"view2\"]\n",
    "    label_labeled_set = labeled_set[\"labels\"]\n",
    "    label_test_set = test_set[\"labels\"]\n",
    "\n",
    "    return (\n",
    "        labeled_set_view1, labeled_set_view2, label_labeled_set,\n",
    "        unlabeled_set,\n",
    "        test_set, test_set[\"labels\"]\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 23ms/step - loss: 0.9072 - accuracy: 0.7000\n",
      "1/7 [===>..........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srina\\AppData\\Local\\Temp\\ipykernel_17148\\3760836582.py:28: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  classifier2.fit(labeled_set_2_2D, labeled_set[\"labels\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 8ms/step\n",
      "7/7 [==============================] - 0s 8ms/step\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.8789 - accuracy: 0.6833\n",
      "418/418 [==============================] - 5s 11ms/step - loss: 1.6589 - accuracy: 0.7049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srina\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 28ms/step - loss: 0.8360 - accuracy: 0.7000\n",
      " 1/13 [=>............................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srina\\AppData\\Local\\Temp\\ipykernel_17148\\3760836582.py:28: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  classifier2.fit(labeled_set_2_2D, labeled_set[\"labels\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 12ms/step\n",
      "13/13 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.8470 - accuracy: 0.7083\n",
      "412/412 [==============================] - 5s 11ms/step - loss: 1.6425 - accuracy: 0.7055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srina\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 26ms/step - loss: 0.8121 - accuracy: 0.7000\n",
      " 1/19 [>.............................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srina\\AppData\\Local\\Temp\\ipykernel_17148\\3760836582.py:28: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  classifier2.fit(labeled_set_2_2D, labeled_set[\"labels\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 10ms/step\n",
      "19/19 [==============================] - 0s 11ms/step\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7888 - accuracy: 0.7000\n",
      "406/406 [==============================] - 5s 11ms/step - loss: 1.5885 - accuracy: 0.6073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srina\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "labeled_set[\"view1\"], labeled_set[\"view2\"], labeled_set[\"labels\"], unlabeled_set, test_set, test_set[\"labels\"] = modified_split_dataset(view1_data, view2_data, unlabeled_size = 200)\n",
    "\n",
    "cnn_acc_5, rf_acc_5 = co_training(cnn_classifier , rf_classifier, \n",
    "                                        labeled_set,\n",
    "                                        unlabeled_set,\n",
    "                                        test_set,\n",
    "                                        threshold_confidence= 0.90)\n",
    "\n",
    "label_prop_accuracy5 = label_propagation(labeled_set[\"view1\"], unlabeled_set[\"view1\"], labeled_set[\"labels\"], test_set[\"view1\"], test_set[\"labels\"], n_neighbors=7)\n",
    "\n",
    "\n",
    "\n",
    "labeled_set[\"view1\"], labeled_set[\"view2\"], labeled_set[\"labels\"], unlabeled_set, test_set, test_set[\"labels\"] = modified_split_dataset(view1_data, view2_data, unlabeled_size = 400)\n",
    "\n",
    "cnn_acc_6, rf_acc_6 = co_training(cnn_classifier , rf_classifier, \n",
    "                                        labeled_set,\n",
    "                                        unlabeled_set,\n",
    "                                        test_set,\n",
    "                                        threshold_confidence= 0.90)\n",
    "\n",
    "label_prop_accuracy6 = label_propagation(labeled_set[\"view1\"], unlabeled_set[\"view1\"], labeled_set[\"labels\"], test_set[\"view1\"], test_set[\"labels\"], n_neighbors=7)\n",
    "\n",
    "\n",
    "\n",
    "labeled_set[\"view1\"], labeled_set[\"view2\"], labeled_set[\"labels\"], unlabeled_set, test_set, test_set[\"labels\"] = modified_split_dataset(view1_data, view2_data, unlabeled_size = 600)\n",
    "\n",
    "cnn_acc_7, rf_acc_7 = co_training(cnn_classifier , rf_classifier, \n",
    "                                        labeled_set,\n",
    "                                        unlabeled_set,\n",
    "                                        test_set,\n",
    "                                        threshold_confidence= 0.90)\n",
    "\n",
    "label_prop_accuracy7 = label_propagation(labeled_set[\"view1\"], unlabeled_set[\"view1\"], labeled_set[\"labels\"], test_set[\"view1\"], test_set[\"labels\"], n_neighbors=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Co-training of unlabeled 200 of CNN Accuracy: [1.6588548421859741, 0.7049314975738525] and Random Forest Accuracy: 0.8861034198907431\n",
      "KNN Accuracy for label propogation for 200 unlabeled size: 0.8088004190675746\n",
      "Co-training of unlabeled 400 of CNN Accuracy: [1.6425343751907349, 0.7054622769355774] and Random Forest Accuracy: 0.8865000379852617\n",
      "KNN Accuracy for label propogation for 400 unlabeled size: 0.809086074603054\n",
      "Co-training of unlabeled 600 of CNN Accuracy: [1.5885318517684937, 0.6072668433189392] and Random Forest Accuracy: 0.8862146108153977\n",
      "KNN Accuracy for label propogation for 600 unlabeled size: 0.8086862608963974\n"
     ]
    }
   ],
   "source": [
    "print(f\"Co-training of unlabeled 200 of CNN Accuracy: {cnn_acc_5} and Random Forest Accuracy: {rf_acc_5}\")\n",
    "print(f\"KNN Accuracy for label propogation for 200 unlabeled size: {label_prop_accuracy5}\")\n",
    "print(f\"Co-training of unlabeled 400 of CNN Accuracy: {cnn_acc_6} and Random Forest Accuracy: {rf_acc_6}\")\n",
    "print(f\"KNN Accuracy for label propogation for 400 unlabeled size: {label_prop_accuracy6}\")\n",
    "print(f\"Co-training of unlabeled 600 of CNN Accuracy: {cnn_acc_7} and Random Forest Accuracy: {rf_acc_7}\")\n",
    "print(f\"KNN Accuracy for label propogation for 600 unlabeled size: {label_prop_accuracy7}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
