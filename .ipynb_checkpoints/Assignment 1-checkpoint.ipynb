{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='text-aling:center;color:Navy'>  Big Data Science - Fall 2023  </h1>\n",
    "<h1 style='text-aling:center;color:Navy'>  Assignment 1  </h1>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Submission Deadline: This assignment is due Friday, November 3 at 8:59 P.M.</b>\n",
    "\n",
    "A few notes before you start:\n",
    "- You are not allowed to use built-in libraries for co-training and label propagation itself.\n",
    "- Directly sharing answers is not okay, but discussing problems with other students is encouraged.\n",
    "- You should start early so that you have time to get help if you're stuck.\n",
    "\n",
    "- Complete all the exercises below and turn in a write-up in the form of a Jupyuter notebook, that is, an .ipynb file. The write-up should include your code and answers to exercise questions. You will submit your assignment online as an attachment (*.ipynb), through Canvas under Assignment 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#3665af\">Semi-Supervised Learning </span>\n",
    "<hr>\n",
    "\n",
    "###### Goal\n",
    "In this assignment, we will explore the concepts and techniques of semi-supervised learning.\n",
    "\n",
    "###### Prerequisites\n",
    "This assignment has the following dependencies:\n",
    "- Jupyter Notebook, along with the following libraries (which should be installed on the Computing Platform):\n",
    "  - Scikit Learn\n",
    "  - Numpy\n",
    "  - os\n",
    "\n",
    "Let's dive into the world of semi-supervised learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:30px;color:#3665af;background-color:#E9E9F5;padding:10px;\">Assignment Hands-on "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:20px;color:#F1F8FC;background-color:#0095EA;padding:10px;\"> Import libraries </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (Dense,\n",
    "                                     Flatten,\n",
    "                                     Dropout,\n",
    "                                     BatchNormalization,\n",
    "                                     Conv2D,\n",
    "                                     MaxPooling2D,)\n",
    "from tensorflow.keras.regularizers import l2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:20px;color:#F1F8FC;background-color:#0095EA;padding:10px;\"> Learn more about the data </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we are working with data collected from two different view from same region via satellite technology to study the Arctic region. These two data types offer valuable insights into various sea ice types, thereby enhancing navigation in the Arctic.\n",
    "\n",
    "1. **Sentinel-1 Data (view 1):** We use Synthetic Aperture Radar (SAR) satellite images from the Sentinel-1 mission. SAR images are incredibly useful for creating sea ice charts in the Arctic. SAR works by sending radar signals to the Earth's surface and capturing the signals that bounce back. One specific view we're utilizing is the Sentinel-1 image captured in HH polarization. This view helps us understand the characteristics of the sea ice in the Arctic. if you want to know more about it here is the [link](https://en.wikipedia.org/wiki/Sentinel-1).\n",
    "\n",
    "2. **AMSR2 Data (view 2):** Alongside each Sentinel-1 image, we have corresponding data from the Advanced Microwave Scanning Radiometer 2 (AMSR2). This dataset contains information about the brightness temperatures of the Earth's surface. AMSR2 measures microwave radiation, which can be used to gather information about surface properties like sea ice concentration. if you want to know more about it here is the [link](https://www.ospo.noaa.gov/Products/atmosphere/gpds/about_amsr2.html).\n",
    "\n",
    "To further analyze these datasets, we selected 10 files and divided the images into smaller patches, each patch 32 by 32 pixels. This patches allows us to focus on specific areas of interest within the Arctic and study them in detail. By combining the information from both Sentinel-1 and AMSR2 data, we can gain a comprehensive understanding of the Arctic environment and its sea ice patterns, which is crucial for various scientific and practical applications, including safe navigation in this challenging region.\n",
    "\n",
    "view 1: Sentinel-1 image\n",
    "\n",
    "<img alt=\"nersc_sar_primary view\" src=\"nersc_sar_primary.jpg\"/>\n",
    "\n",
    "view 2: AMSR2 image\n",
    "\n",
    "<img src=\"btemp_89_0h.jpg\" alt = \"btemp_89_0h view\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the data.zip file from Canvas, and then execute the cell below to import the data. You can customize the directory name for the data if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " shape view 1 data:  (13683, 32, 32)\n",
      " shape view 2 data:  (13683, 32, 32)\n",
      " shape labels data:  (13683, 1)\n"
     ]
    }
   ],
   "source": [
    "def load_data_from_directories(view1_dir, view2_dir, labels_dir):\n",
    "    \"\"\"\n",
    "    Load data from directories containing two views and corresponding labels.\n",
    "\n",
    "    Parameters:\n",
    "    - view1_dir (str): Path to the directory containing view 1 data files.\n",
    "    - view2_dir (str): Path to the directory containing view 2 data files.\n",
    "    - labels_dir (str): Path to the directory containing label data files.\n",
    "\n",
    "    Returns:\n",
    "    - view1_data (numpy.ndarray): NumPy array containing data from view 1.\n",
    "    - view2_data (numpy.ndarray): NumPy array containing data from view 2.\n",
    "    - labels_data (numpy.ndarray): NumPy array containing label data.\n",
    "\n",
    "    This function loads data from two views and their corresponding labels, assuming a common \"number\" part\n",
    "    in the file names for matching files. It ensures that data files from both views and labels are consistent\n",
    "    and loads them into NumPy arrays for further processing.\n",
    "    \"\"\"\n",
    "    # List all files in each directory\n",
    "    files_view1 = os.listdir(view1_dir)\n",
    "    files_view2 = os.listdir(view2_dir)\n",
    "    files_label = os.listdir(labels_dir)\n",
    "\n",
    "    # Initialize empty lists to store data from each view and labels\n",
    "    view1_data = []\n",
    "    view2_data = []\n",
    "    labels_data = []\n",
    "\n",
    "    # Iterate through the files in the directory\n",
    "    for filename in files_view1:\n",
    "        if filename.endswith('_samples_view1.npy'):\n",
    "            # Extract the common \"number\" part of the file name\n",
    "            common_number = filename.split('_')[0]\n",
    "\n",
    "            # Check if corresponding files exist for view2 and labels\n",
    "            if common_number + '_samples_view2.npy' in files_view2 and common_number + '_labels.npy' in files_label:\n",
    "                # Load data from the NumPy files\n",
    "                data_view1 = np.load(os.path.join(view1_dir, filename))\n",
    "                data_view2 = np.load(os.path.join(view2_dir, common_number + '_samples_view2.npy'))\n",
    "                data_labels = np.load(os.path.join(labels_dir, common_number + '_labels.npy'))\n",
    "\n",
    "                # Append data to respective lists\n",
    "                view1_data.append(data_view1)\n",
    "                view2_data.append(data_view2)\n",
    "                labels_data.append(data_labels)\n",
    "\n",
    "    view1_data = np.array(view1_data)\n",
    "    view2_data = np.array(view2_data)\n",
    "    labels_data = np.array(labels_data)\n",
    "\n",
    "    return view1_data, view2_data, labels_data\n",
    "\n",
    "\n",
    "view1_dir = 'C:/Users/srina/Documents/Big Data science/data/view1/' \n",
    "view2_dir = 'C:/Users/srina/Documents/Big Data science/data/view2/' \n",
    "labels_dir = 'C:/Users/srina/Documents/Big Data science/data/labels/' \n",
    "\n",
    "view1_data, view2_data, labels_data = load_data_from_directories(view1_dir, view2_dir, labels_dir)\n",
    "\n",
    "\n",
    "print(\" shape view 1 data: \", view1_data.shape)\n",
    "print(\" shape view 2 data: \", view2_data.shape)\n",
    "print(\" shape labels data: \", labels_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:20px;color:#F1F8FC;background-color:#0095EA;padding:10px;\">Part  1. Co-Training Models for Sea Ice Classification</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you'll be applying the Co-training technique to the dataset. Through this, you'll observe the outcomes of both semi-supervised learning and supervised learning when there's only a limited amount of labeled data available. You may want to revisit Lecture 02, which covers the topic of cotraining for a more comprehensive understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-1. Divide the dataset into three distinct sets: one for labeled data, one for unlabeled data, and one for test data. Make sure that the labeled dataset contains between 100 and 130 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Please write your code here. Comments are provided for guidance purposes. make adjustments as needed.\n",
    "def split_dataset(dataset_view1, dataset_view2, labeled_size, test_size=0.2, random_seed=42):\n",
    "    \"\"\"\n",
    "    Split the dataset into labeled, unlabeled, and test sets.\n",
    "\n",
    "    Parameters:\n",
    "    - dataset (list or array-like): The input dataset to be split.\n",
    "    - labeled_size (int): The target size for the labeled set (default: 130).\n",
    "    - test_size (float): The proportion of the dataset to include in the test split (default: 0.2).\n",
    "    - random_seed (int): Seed for reproducibility (default: None).\n",
    "\n",
    "    Returns:\n",
    "    - labeled_set_view1: Subset of the dataset with labeled data (approximately 100-130 points).\n",
    "    - labeled_set_view2: Subset of the dataset with labeled data (approximately 100-130 points).\n",
    "    - label_labeled_set: Labels corresponding to the labeled data points.\n",
    "    - unlabeled_set: Subset of the dataset with unlabeled data.\n",
    "    - test_set: Subset of the dataset for testing.\n",
    "    - label_test_set: Labels corresponding to the test data points.\n",
    "    \"\"\"\n",
    "    # First, let's create a common index for shuffling and splitting the data\n",
    "    num_samples = len(dataset_view1)\n",
    "    indices = np.arange(num_samples)\n",
    "\n",
    "    # Shuffle the indices for random sampling\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    # Determine the number of labeled data points\n",
    "\n",
    "    # Calculate the number of labeled and test data points\n",
    "    n_labeled = int(labeled_size)\n",
    "    n_test = int(test_size * num_samples)\n",
    "\n",
    "    # Split the data into labeled, unlabeled, and test sets\n",
    "    labeled_indices = indices[:n_labeled]\n",
    "    test_indices = indices[n_labeled:n_labeled + n_test]\n",
    "    unlabeled_indices = indices[n_labeled + n_test:]\n",
    "\n",
    "    labeled_set_view1 = dataset_view1[labeled_indices]\n",
    "    labeled_set_view2 = dataset_view2[labeled_indices]\n",
    "    label_labeled_set = labels_data[labeled_indices]  # You need to provide the labels\n",
    "\n",
    "    unlabeled_set_view1 = dataset_view1[unlabeled_indices]\n",
    "    unlabeled_set_view2 = dataset_view2[unlabeled_indices]\n",
    "\n",
    "    test_set_view1 = dataset_view1[test_indices]\n",
    "    test_set_view2 = dataset_view2[test_indices]\n",
    "    label_test_set = labels_data[test_indices]  # You need to provide the labels\n",
    "\n",
    "    return labeled_set_view1, labeled_set_view2, label_labeled_set, unlabeled_set_view1, unlabeled_set_view2, test_set_view1, test_set_view2, label_test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-2. initialize two classifiers for each view using scikit-learn. Consider using a Convolutional Neural Network (CNN) as one of the classifiers and a Random Forest as the other.\n",
    "Here's a short description of the configuration for the CNN (Convolutional Neural Network) and Random Forest (RF) classifiers to implement:\n",
    "\n",
    "**CNN Classifier Configuration:**\n",
    "\n",
    "1. Input Layer: BatchNormalization with input shape (32, 32, 1).\n",
    "2. Convolutional Layer 1: 32 filters, each with a 3x3 kernel and ReLU activation.\n",
    "3. Max Pooling Layer 1: 2x2 pooling with a stride of 2.\n",
    "4. Convolutional Layer 2: 32 filters, each with a 3x3 kernel and ReLU activation.\n",
    "5. Max Pooling Layer 2: 2x2 pooling with a stride of 2.\n",
    "6. Convolutional Layer 3: 32 filters, each with a 3x3 kernel and ReLU activation.\n",
    "7. Max Pooling Layer 3: 2x2 pooling with a stride of 2.\n",
    "8. BatchNormalization Layer.\n",
    "9. Flatten Layer.\n",
    "10. Dropout Layer with a dropout rate of 0.1.\n",
    "11. Fully Connected Layer 1: 16 neurons, ReLU activation, and L2 regularization with a weight decay of 0.001.\n",
    "12. Dropout Layer with a dropout rate of 0.1.\n",
    "13. Fully Connected Layer 2: 16 neurons, ReLU activation, and L2 regularization with a weight decay of 0.001.\n",
    "14. Dropout Layer with a dropout rate of 0.1.\n",
    "15. Output Layer: Dense layer with the number of neurons equal to the number of classes and softmax activation.\n",
    "\n",
    "**CNN Model Compilation:**\n",
    "- Optimizer: Adam\n",
    "- Loss Function: Sparse Categorical Crossentropy\n",
    "- Metrics for Evaluation: Accuracy\n",
    "\n",
    "**Random Forest Classifier Configuration:**\n",
    "- Number of Estimators: 20\n",
    "- Random State: 42\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 6\n",
    "# write your code here\n",
    "#implement classifiers based on the provided definition\n",
    "#cnn_classifier =\n",
    "#rf_classifier =\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import numpy as np\n",
    "\n",
    "# Define the configuration for the CNN classifier\n",
    "cnn_classifier = Sequential([\n",
    "    Input(shape=(32, 32, 1)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=2),\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=2),\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=2),\n",
    "    BatchNormalization(),\n",
    "    Flatten(),\n",
    "    Dropout(0.1),\n",
    "    Dense(16, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    Dropout(0.1),\n",
    "    Dense(16, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    Dropout(0.1),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_classifier.compile(optimizer='adam',\n",
    "                       loss='sparse_categorical_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Define the configuration for the Random Forest classifier\n",
    "def rf_classifier(num_estimators=20, random_state=42):\n",
    "    return RandomForestClassifier(n_estimators=num_estimators, random_state=random_state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-3. Do the co-training part:\n",
    "   - Train classifiers on the labeled data\n",
    "   - Predict on the unlabeled data and identify instances that have a confidence score more than 90.\n",
    "   - Add the confident instances to the labeled set and train again\n",
    "   - Compute the accuracy of the classifiers on test set\n",
    "To provide a more understanding of the accuracy measure, please refer to the following link: [link](https://en.wikipedia.org/wiki/Accuracy_and_precision).\n",
    "<img src=\"accuracy.jpg\" alt = \"accuracy metric\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    " # Please write your code here. Comments are provided for guidance purposes. make adjustments as needed.\n",
    "def co_training(classifier1, classifier2, labeled_set_1, labeled_set_2, label_labeled_set, unlabeled_set_1, unlabeled_set_2, test_set_1, test_set_2 , label_test_set, threshold_confidence):\n",
    "    \"\"\"\n",
    "    Perform co-training with two classifiers on labeled and unlabeled data.\n",
    "\n",
    "    Parameters:\n",
    "    - classifier1: The first classifier (e.g., CNN).\n",
    "    - classifier2: The second classifier (e.g., Random Forest).\n",
    "    - labeled_set (list or array-like): Labeled dataset.\n",
    "    - unlabeled_set (list or array-like): Unlabeled dataset.\n",
    "    - test_set (list or array-like): Test dataset.\n",
    "    - threshold_confidence (float): The minimum confidence threshold for adding unlabeled samples to the training set.\n",
    "\n",
    "    Returns:\n",
    "    - classifier1_accuracy (float): Accuracy of Classifier 1 on the test set after co-training.\n",
    "    - classifier2_accuracy (float): Accuracy of Classifier 2 on the test set after co-training.\n",
    "    \"\"\"\n",
    "    \n",
    "    samples_1, x1, y1 = labeled_set_2.shape\n",
    "    labeled_set_2_2D = labeled_set_2.reshape((samples_1,x1*y1))\n",
    "    \n",
    "    samples_2, x2, y2 = unlabeled_set_2.shape\n",
    "    unlabeled_set_2_2D = unlabeled_set_2.reshape((samples_2,x2*y2))\n",
    "    \n",
    "    samples_3, x3, y3 = test_set_2.shape\n",
    "    test_set_2_2D = test_set_2.reshape((samples_3,x3*y3))\n",
    "    \n",
    "    classifier1.fit(labeled_set_1, label_labeled_set)\n",
    "    classifier2.fit(labeled_set_2_2D, label_labeled_set)\n",
    "\n",
    "    # Loop for co-training iterations\n",
    "   \n",
    "    # Predict on unlabeled data\n",
    "    predictions1 = classifier1.predict(unlabeled_set_1)\n",
    "    predictions2 = classifier2.predict(unlabeled_set_2_2D)\n",
    "\n",
    "    # Confidence scores for the predictions\n",
    "    confidences1 = np.max(classifier1.predict(unlabeled_set_1), axis=1)\n",
    "    confidences2 = np.max(classifier2.predict_proba(unlabeled_set_2_2D), axis=1)\n",
    "\n",
    "    # Identify instances with high confidence for both classifiers\n",
    "    confident_samples_1 = np.where(confidences1 > threshold_confidence)[0]\n",
    "    confident_samples_2 = np.where(confidences2 > threshold_confidence)[0]\n",
    "\n",
    "    print(confident_samples_1.shape)\n",
    "    print(confident_samples_1)\n",
    "    # Add confident samples to the labeled set and remove them from the unlabeled set\n",
    "    labeled_set_1 = np.vstack((labeled_set_1, unlabeled_set_1[confident_samples_1]))\n",
    "    label_labeled_set_1 = np.append(label_labeled_set, predictions1[confident_samples_1])\n",
    "        \n",
    "    labeled_set_2_2D = np.vstack((labeled_set_2_2D, unlabeled_set_2_2D[confident_samples_2]))\n",
    "    label_labeled_set_2 = np.append(label_labeled_set, predictions2[confident_samples_2])\n",
    "\n",
    "    # Remove confident samples from the unlabeled set\n",
    "    unlabeled_set_1 = np.delete(unlabeled_set_1, confident_samples_1, axis=0)\n",
    "    unlabeled_set_2_2D = np.delete(unlabeled_set_2_2D, confident_samples_2, axis=0)\n",
    "\n",
    "    # Retrain the classifiers with the updated labeled set\n",
    "    classifier1.fit(labeled_set_1, label_labeled_set_1)\n",
    "    classifier2.fit(labeled_set_2_2D, label_labeled_set_2)\n",
    "\n",
    "    # Compute accuracy on the test set\n",
    "    classifier1_accuracy = classifier1.evaluate(test_set_1, label_test_set)\n",
    "    classifier2_accuracy = classifier2.score(test_set_2_2D, label_test_set)\n",
    "\n",
    "    return classifier1_accuracy, classifier2_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-4. pick one of the classifiers and do the supervised training with the labeled data and calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Please write your code here. Comments are provided for guidance purposes. make adjustments as needed.\n",
    "def supervised_training_and_accuracy(classifier, labeled_data, labeled_labels, test_data, test_labels):\n",
    "    \"\"\"\n",
    "    Perform supervised training with a classifier on the labeled data and calculate the accuracy on test data.\n",
    "\n",
    "    Parameters:\n",
    "    - classifier: The classifier to be used for supervised training (e.g., Random Forest).\n",
    "    - labeled_data (array-like): Labeled training data.\n",
    "    - labeled_labels (array-like): Labels for the labeled training data.\n",
    "    - test_data (array-like): Test data for evaluation.\n",
    "    - test_labels (array-like): Labels for the test data.\n",
    "\n",
    "    Returns:\n",
    "    - accuracy (float): Accuracy of the classifier on the test data after supervised training.\n",
    "    \"\"\"\n",
    "    samples_1, x1, y1 = labeled_data.shape\n",
    "    labeled_set_2_2D = labeled_data.reshape((samples_1,x1*y1))\n",
    "    \n",
    "    samples_3, x3, y3 = test_data.shape\n",
    "    test_set_2_2D = test_data.reshape((samples_3,x3*y3))\n",
    "    \n",
    "    classifier.fit(labeled_set_2_2D, labeled_labels)\n",
    "    accuracy = classifier.score(test_set_2_2D, test_labels)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-5. Compare the Co-training approach accuracy and supervised model with limited labeled data and write your reason about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 28ms/step - loss: 0.6861 - accuracy: 0.8083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srina\\AppData\\Local\\Temp\\ipykernel_19760\\2784568044.py:29: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  classifier2.fit(labeled_set_2_2D, label_labeled_set)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 3s 9ms/step\n",
      "339/339 [==============================] - 3s 9ms/step\n",
      "(0,)\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6504 - accuracy: 0.8000\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 1.5682 - accuracy: 0.8147\n",
      "Co-training CNN Accuracy: [1.568174123764038, 0.8146929740905762]\n",
      "Co-training Random Forest Accuracy: 0.893640350877193\n",
      "Supervised Random Forest Accuracy: 0.8636695906432749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srina\\AppData\\Local\\Temp\\ipykernel_19760\\1336973450.py:22: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  classifier.fit(labeled_set_2_2D, labeled_labels)\n"
     ]
    }
   ],
   "source": [
    "# Define the number of classes in your dataset (update this accordingly)\n",
    "num_classes = 6\n",
    "\n",
    "# Split the dataset into labeled, unlabeled, and test sets\n",
    "labeled_set_view1, labeled_set_view2, label_labeled_set, unlabeled_set_view1, unlabeled_set_view2, test_set_view1, test_set_view2, label_test_set = split_dataset(view1_data, view2_data, labeled_size= 120)\n",
    "\n",
    "\n",
    "classifier_rf = rf_classifier(num_estimators=20, random_state=42)\n",
    "\n",
    "# Co-training\n",
    "cnn_accuracy, rf_accuracy = co_training(classifier1=cnn_classifier , classifier2=classifier_rf, \n",
    "                                        labeled_set_1=labeled_set_view1, labeled_set_2=labeled_set_view2,label_labeled_set=label_labeled_set,\n",
    "                                        unlabeled_set_1=unlabeled_set_view1, unlabeled_set_2=unlabeled_set_view2,\n",
    "                                        test_set_1=test_set_view1, test_set_2=test_set_view2, label_test_set=label_test_set,\n",
    "                                        threshold_confidence= 0.90)\n",
    "\n",
    "# Supervised training with one of the classifiers (e.g., Random Forest)\n",
    "rf_supervised_accuracy = supervised_training_and_accuracy(classifier_rf, labeled_set_view2, label_labeled_set, test_set_view2, label_test_set)\n",
    "\n",
    "# Compare accuracies\n",
    "print(f\"Co-training CNN Accuracy: {cnn_accuracy}\")\n",
    "print(f\"Co-training Random Forest Accuracy: {rf_accuracy}\")\n",
    "print(f\"Supervised Random Forest Accuracy: {rf_supervised_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:20px;color:#F1F8FC;background-color:#0095EA;padding:10px;\">Part 2. Label Propagation for Sea Ice Classification</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you'll be applying the label propagation technique to the dataset. Through this, you'll observe the outcomes of both semi-supervised learning and supervised learning when there's only a limited amount of labeled data available.\n",
    "\n",
    "\n",
    "<img src=\"label_propagation.jpg\" alt = \"label propgation process\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 2-1. Apply the K-Nearest Neighbors (KNN) algorithm with a parameter configuration where n_neighbors is set to 7 for the label propagation model. Utilize one of the labeled data views and the corresponding unlabeled data from part 1 as input.\n",
    "To provide a more understanding of the accuracy measure, please refer to the following link: [link](https://en.wikipedia.org/wiki/Accuracy_and_precision)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srina\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy for label propogation: 0.8088450292397661\n"
     ]
    }
   ],
   "source": [
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Please write your code here. Comments are provided for guidance purposes. make adjustments as needed.\n",
    "def label_propagation(labeled_data, unlabeled_data, labeled_labels, test_data, label_test, n_neighbors):\n",
    "    \"\"\"\n",
    "    Apply K-Nearest Neighbors (KNN) to the label propagation model on one data view and test data.\n",
    "\n",
    "    Parameters:\n",
    "    - labeled_data (array-like): Labeled data points.\n",
    "    - unlabeled_data (array-like): Unlabeled data points.\n",
    "    - labeled_labels (array-like): Labels corresponding to the labeled data points.\n",
    "    - test_data (array-like): Test data to evaluate label propagation performance.\n",
    "    - label_test (array-like): Labels corresponding to the test data points.\n",
    "    - n_neighbors (int): Number of neighbors to consider in KNN (default: 7).\n",
    "\n",
    "    Returns:\n",
    "    - accuracy (float): Accuracy of label propagation on the test data.\n",
    "    \"\"\"\n",
    "    \n",
    "    samples_1, x1, y1 = labeled_data.shape\n",
    "    labeled_set_1_2D = labeled_data.reshape((samples_1,x1*y1))\n",
    "    \n",
    "    samples_2, x2, y2 = unlabeled_data.shape\n",
    "    unlabeled_set_1_2D = unlabeled_data.reshape((samples_2,x2*y2))\n",
    "    \n",
    "    samples_3, x3, y3 = test_data.shape\n",
    "    test_set_1_2D = test_data.reshape((samples_3,x3*y3))\n",
    "    \n",
    "    label_prop_model = LabelPropagation(kernel=\"knn\", n_neighbors=n_neighbors, max_iter=1000)\n",
    "    \n",
    "    # Fit the model\n",
    "    label_prop_model.fit(labeled_set_1_2D, labeled_labels)\n",
    "    \n",
    "    # Predict labels for the test data\n",
    "    predicted_labels = label_prop_model.predict(unlabeled_set_1_2D)\n",
    "    \n",
    "    data_combined = np.vstack([labeled_set_1_2D, unlabeled_set_1_2D])\n",
    "    \n",
    "    all_labels = np.concatenate([labeled_labels.flatten(), predicted_labels])\n",
    "    \n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "\n",
    "    # Fit the KNN classifier on the labeled data\n",
    "    knn_classifier.fit(data_combined, all_labels)\n",
    "\n",
    "    # Predict labels for the test data\n",
    "    test_predicted_labels = knn_classifier.predict(test_set_1_2D)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(label_test, test_predicted_labels)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "label_prop_accuracy = label_propagation(labeled_set_view1, unlabeled_set_view1, label_labeled_set, test_set_view1, label_test_set, n_neighbors=7)\n",
    "\n",
    "print(f\"KNN Accuracy for label propogation: {label_prop_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-2. Select a classification algorithm and perform supervised learning on the labeled set. Then, evaluate the model's performance by calculating the accuracy. You can use a built-in library for the classifier. Compare your sepervised and semi supervised accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supervised training accuracy: 0.8636695906432749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srina\\AppData\\Local\\Temp\\ipykernel_19760\\1649951280.py:23: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  classifier.fit(labeled_set_1_2D, labeled_labels)\n"
     ]
    }
   ],
   "source": [
    "# Please write your code here. Comments are provided for guidance purposes. make adjustments as needed.\n",
    "def supervised_training_and_accuracy(classifier, labeled_data, labeled_labels, test_data, test_labels):\n",
    "    \"\"\"\n",
    "    Perform supervised training with a classifier on the labeled data and calculate the accuracy on test data.\n",
    "\n",
    "    Parameters:\n",
    "    - classifier: The classifier to be used for supervised training (e.g., Random Forest).\n",
    "    - labeled_data (array-like): Labeled training data.\n",
    "    - labeled_labels (array-like): Labels for the labeled training data.\n",
    "    - test_data (array-like): Test data for evaluation.\n",
    "    - test_labels (array-like): Labels for the test data.\n",
    "\n",
    "    Returns:\n",
    "    - accuracy (float): Accuracy of the classifier on the test data after supervised training.\n",
    "    \"\"\"\n",
    "    \n",
    "    samples_1, x1, y1 = labeled_data.shape\n",
    "    labeled_set_1_2D = labeled_data.reshape((samples_1,x1*y1))\n",
    "    \n",
    "    samples_2, x2, y2 = test_data.shape\n",
    "    test_data_1_2D = test_data.reshape((samples_2,x2*y2))\n",
    "    \n",
    "    classifier.fit(labeled_set_1_2D, labeled_labels)\n",
    "    \n",
    "    # Predict on test data\n",
    "    predictions = classifier.predict(test_data_1_2D)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(test_labels, predictions)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "rnd_f_accuracy = supervised_training_and_accuracy(classifier_rf, labeled_set_view1, label_labeled_set, test_set_view1, label_test_set)\n",
    "\n",
    "print(f\"Supervised training accuracy: {rnd_f_accuracy}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:20px;color:#F1F8FC;background-color:#0095EA;padding:10px;\">Part 3. Now let's perform some experimentation and make some observations!</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-1. We will explore the impact of varying the threshold confidence in the co-training process at three different values: 80, 70, and 60. We will then assess the accuracy of co-training based on these threshold settings.\n",
    "To provide a more understanding of the accuracy measure, please refer to the following link: [link](https://en.wikipedia.org/wiki/Accuracy_and_precision)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 57ms/step - loss: 1.7540 - accuracy: 0.0750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srina\\AppData\\Local\\Temp\\ipykernel_19760\\3695694683.py:29: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  classifier2.fit(labeled_set_2_2D, label_labeled_set)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 3s 9ms/step\n",
      "339/339 [==============================] - 3s 8ms/step\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.7438 - accuracy: 0.1083\n",
      "86/86 [==============================] - 1s 9ms/step - loss: 1.8211 - accuracy: 0.0939\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.6668 - accuracy: 0.1917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srina\\AppData\\Local\\Temp\\ipykernel_19760\\3695694683.py:29: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  classifier2.fit(labeled_set_2_2D, label_labeled_set)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 3s 9ms/step\n",
      "339/339 [==============================] - 3s 10ms/step\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.6187 - accuracy: 0.2750\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 1.8119 - accuracy: 0.3805\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 1.5082 - accuracy: 0.4250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srina\\AppData\\Local\\Temp\\ipykernel_19760\\3695694683.py:29: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  classifier2.fit(labeled_set_2_2D, label_labeled_set)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 3s 10ms/step\n",
      "339/339 [==============================] - 3s 8ms/step\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.4793 - accuracy: 0.3583\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 1.7966 - accuracy: 0.7336\n",
      "Co-training of CNN Accuracy: [1.8210883140563965, 0.09393274784088135] and Random Forest Accuracy: 0.893640350877193\n",
      "Co-training of CNN Accuracy: [1.8118579387664795, 0.3804824650287628] and Random Forest Accuracy: 0.893640350877193\n",
      "Co-training of CNN Accuracy: [1.7965501546859741, 0.7335526347160339] and Random Forest Accuracy: 0.893640350877193\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "cnn_accuracy_1, rf_accuracy_1 = co_training(classifier1=cnn_classifier , classifier2=classifier_rf, \n",
    "                                        labeled_set_1=labeled_set_view1, labeled_set_2=labeled_set_view2,label_labeled_set=label_labeled_set,\n",
    "                                        unlabeled_set_1=unlabeled_set_view1, unlabeled_set_2=unlabeled_set_view2,\n",
    "                                        test_set_1=test_set_view1, test_set_2=test_set_view2, label_test_set=label_test_set,\n",
    "                                        threshold_confidence= 0.80)\n",
    "\n",
    "cnn_accuracy_2, rf_accuracy_2 = co_training(classifier1=cnn_classifier , classifier2=classifier_rf, \n",
    "                                        labeled_set_1=labeled_set_view1, labeled_set_2=labeled_set_view2,label_labeled_set=label_labeled_set,\n",
    "                                        unlabeled_set_1=unlabeled_set_view1, unlabeled_set_2=unlabeled_set_view2,\n",
    "                                        test_set_1=test_set_view1, test_set_2=test_set_view2, label_test_set=label_test_set,\n",
    "                                        threshold_confidence= 0.70)\n",
    "\n",
    "cnn_accuracy_3, rf_accuracy_3 = co_training(classifier1=cnn_classifier , classifier2=classifier_rf, \n",
    "                                        labeled_set_1=labeled_set_view1, labeled_set_2=labeled_set_view2,label_labeled_set=label_labeled_set,\n",
    "                                        unlabeled_set_1=unlabeled_set_view1, unlabeled_set_2=unlabeled_set_view2,\n",
    "                                        test_set_1=test_set_view1, test_set_2=test_set_view2, label_test_set=label_test_set,\n",
    "                                        threshold_confidence= 0.60)\n",
    "\n",
    "print(f\"Co-training of CNN Accuracy: {cnn_accuracy_1} and Random Forest Accuracy: {rf_accuracy_1}\")\n",
    "print(f\"Co-training of CNN Accuracy: {cnn_accuracy_2} and Random Forest Accuracy: {rf_accuracy_2}\")\n",
    "print(f\"Co-training of CNN Accuracy: {cnn_accuracy_3} and Random Forest Accuracy: {rf_accuracy_3}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-2. Change the parameters of the K-Nearest Neighbors (KNN) algorithm for Label Propagation (part 2) with the values 3, 5, and 10, and explain what you understand about these parameter adjustments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srina\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\srina\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\srina\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy for label propogation for 3: 0.8212719298245614\n",
      "KNN Accuracy for label propogation for 5: 0.8212719298245614\n",
      "KNN Accuracy for label propogation for 10: 0.8088450292397661\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "label_prop_accuracy_1 = label_propagation(labeled_set_view1, unlabeled_set_view1, label_labeled_set, test_set_view1, label_test_set, n_neighbors=3)\n",
    "label_prop_accuracy_2 = label_propagation(labeled_set_view1, unlabeled_set_view1, label_labeled_set, test_set_view1, label_test_set, n_neighbors=5)\n",
    "label_prop_accuracy_3 = label_propagation(labeled_set_view1, unlabeled_set_view1, label_labeled_set, test_set_view1, label_test_set, n_neighbors=10)\n",
    "\n",
    "\n",
    "print(f\"KNN Accuracy for label propogation for 3: {label_prop_accuracy_1}\")\n",
    "print(f\"KNN Accuracy for label propogation for 5: {label_prop_accuracy_2}\")\n",
    "print(f\"KNN Accuracy for label propogation for 10: {label_prop_accuracy_3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "3-3. Let's see the impact of of a simplifies models for cotraining approach.\n",
    "- Reduce the number of convolutional layers in the question 1-2 from 3 to 1 convolution layer and the rest of the layers is the same\n",
    "- Change the number of trees for the random forest algorithm to 1.\n",
    "Evaluate the performance of cotraining approach.\n",
    "- Additionally, use the 1 layer convolution layer as the supervised model and evaluate the performance for supervised learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 26ms/step - loss: 4.0224 - accuracy: 0.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srina\\AppData\\Local\\Temp\\ipykernel_19760\\3695694683.py:29: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  classifier2.fit(labeled_set_2_2D, label_labeled_set)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339/339 [==============================] - 4s 11ms/step\n",
      "339/339 [==============================] - 2s 6ms/step\n",
      "4/4 [==============================] - 1s 26ms/step - loss: 3.1660 - accuracy: 0.1833\n",
      "86/86 [==============================] - 1s 6ms/step - loss: 1.8912 - accuracy: 0.1893\n",
      "Co-training of CNN Accuracy: [1.8911731243133545, 0.18932747840881348] and Random Forest Accuracy: 0.8154239766081871\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 2.4265 - accuracy: 0.1917\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 1.8018 - accuracy: 0.1941\n",
      "Supervised 1 layer CNN Accuracy: [1.8017785549163818, 0.1940789520740509]\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "cnn_classifier_1 = Sequential([\n",
    "    Input(shape=(32, 32, 1)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=2),\n",
    "    BatchNormalization(),\n",
    "    Flatten(),\n",
    "    Dropout(0.1),\n",
    "    Dense(16, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    Dropout(0.1),\n",
    "    Dense(16, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    Dropout(0.1),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_classifier_1.compile(optimizer='adam',\n",
    "                       loss='sparse_categorical_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "\n",
    "classifier_rf_1 = rf_classifier(num_estimators=1, random_state=42)\n",
    "\n",
    "\n",
    "cnn_acc, rf_acc = co_training(classifier1=cnn_classifier_1 , classifier2=classifier_rf_1, \n",
    "                                        labeled_set_1=labeled_set_view1, labeled_set_2=labeled_set_view2,label_labeled_set=label_labeled_set,\n",
    "                                        unlabeled_set_1=unlabeled_set_view1, unlabeled_set_2=unlabeled_set_view2,\n",
    "                                        test_set_1=test_set_view1, test_set_2=test_set_view2, label_test_set=label_test_set,\n",
    "                                        threshold_confidence= 0.90)\n",
    "\n",
    "print(f\"Co-training of CNN Accuracy: {cnn_acc} and Random Forest Accuracy: {rf_acc}\")\n",
    "\n",
    "def supervised_training_and_accuracy(classifier, labeled_data, labeled_labels, test_data, test_labels):\n",
    "    classifier.fit(labeled_data, labeled_labels)\n",
    "    accuracy = classifier.evaluate(test_data, test_labels)\n",
    "    return accuracy\n",
    "\n",
    "supervised_acc = supervised_training_and_accuracy(cnn_classifier_1, labeled_set_view1, label_labeled_set, test_set_view1, label_test_set)\n",
    "\n",
    "print(f\"Supervised 1 layer CNN Accuracy: {supervised_acc}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-4. Let's adjust the amount of labeled data in part 2 by considering two different quantities: 200 and 400 labeled data points. In each scenario, the remaining data will remain unlabeled. Evaluate the performance of label propagation under these labeled data scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srina\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\srina\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy for label propogation for labeled size of 200: 0.8870614035087719\n",
      "KNN Accuracy for label propogation for labeled size of 400: 0.8863304093567251\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "labeled_set_view3, labeled_set_view4, label_labeled_set2, unlabeled_set_view3, unlabeled_set_view4, test_set_view3, test_set_view4, label_test_set2 = split_dataset(view1_data, view2_data, labeled_size=200)\n",
    "\n",
    "labeled_set_view5, labeled_set_view6, label_labeled_set3, unlabeled_set_view5, unlabeled_set_view6, test_set_view5, test_set_view6, label_test_set3 = split_dataset(view1_data, view2_data, labeled_size=400)\n",
    "\n",
    "label_prop_accuracy2 = label_propagation(labeled_set_view3, unlabeled_set_view3, label_labeled_set2, test_set_view3, label_test_set2, n_neighbors=7)\n",
    "\n",
    "label_prop_accuracy3 = label_propagation(labeled_set_view5, unlabeled_set_view5, label_labeled_set3, test_set_view5, label_test_set3, n_neighbors=7)\n",
    "\n",
    "print(f\"KNN Accuracy for label propogation for labeled size of 200: {label_prop_accuracy2}\")\n",
    "print(f\"KNN Accuracy for label propogation for labeled size of 400: {label_prop_accuracy3}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3-5. Let's adjust the number of labeled data samples for part 1. Consider three scenarios: one with 200 labeled samples, another with 400 labeled samples, and a third with 600 labeled samples. In each scenario, the remaining data will remain unlabeled. Additionally, include an explanation of your understanding of how these parameter changes impact the algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "# Please write your code here. Comments are provided for guidance purposes. make adjustments as needed.\n",
    "def updated_split_dataset(dataset_view1, dataset_view2, labeled_size, random_seed=42):\n",
    "    num_samples = len(dataset_view1)\n",
    "    indices = np.arange(num_samples)\n",
    "\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    num_labeled = int(labeled_size)\n",
    "\n",
    "    labeled_indices = indices[:num_labeled]\n",
    "    unlabeled_indices = indices[num_labeled:]\n",
    "\n",
    "    labeled_set_view1 = dataset_view1[labeled_indices]\n",
    "    labeled_set_view2 = dataset_view2[labeled_indices]\n",
    "    label_labeled_set = labels_data[labeled_indices]  \n",
    "\n",
    "    unlabeled_set_view1 = dataset_view1[unlabeled_indices]\n",
    "    unlabeled_set_view2 = dataset_view2[unlabeled_indices]\n",
    "\n",
    "    return labeled_set_view1, labeled_set_view2, label_labeled_set, unlabeled_set_view1, unlabeled_set_view2\n",
    "\n",
    "labeled_set_view7, labeled_set_view8, label_labeled_set4, unlabeled_set_view7, unlabeled_set_view8 = updated_split_dataset(view1_data, view2_data, labeled_size= 200)\n",
    "\n",
    "labeled_set_view9, labeled_set_view10, label_labeled_set5, unlabeled_set_view9, unlabeled_set_view10 = updated_split_dataset(view1_data, view2_data, labeled_size= 400)\n",
    "\n",
    "labeled_set_view11, labeled_set_view12, label_labeled_set6, unlabeled_set_view11, unlabeled_set_view12 = updated_split_dataset(view1_data, view2_data, labeled_size= 600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 32, 32)\n",
      "(13483, 32, 32)\n",
      "(400, 32, 32)\n",
      "(13283, 32, 32)\n",
      "(600, 32, 32)\n",
      "(13083, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "print(labeled_set_view7.shape)\n",
    "print(unlabeled_set_view7.shape)\n",
    "print(labeled_set_view9.shape)\n",
    "print(unlabeled_set_view10.shape)\n",
    "print(labeled_set_view11.shape)\n",
    "print(unlabeled_set_view12.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3-6. Evalute the perfomance for different number of unlabeled data size.\n",
    "- Set labeled data size within the range of 100 to 130 and\n",
    "- Set the unlabeled data sizes at 200, 400, and 600.\n",
    "- Execute the algorithms and provide accuracy reports for both approaches: co-training and label propagation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def Reupdated_split_dataset(dataset_view1, dataset_view2, labeled_size, unlabeled_size, random_seed=42):\n",
    "\n",
    "    # First, let's create a common index for shuffling and splitting the data\n",
    "    num_samples = len(dataset_view1)\n",
    "    indices = np.arange(num_samples)\n",
    "\n",
    "    # Shuffle the indices for random sampling\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    # Determine the number of labeled data points\n",
    "    labeled_size = int(labeled_size)\n",
    "\n",
    "    # Calculate the number of labeled and test data points\n",
    "    num_labeled = int(labeled_size)\n",
    "    num_unlabeled = int(unlabeled_size)\n",
    "\n",
    "    # Split the data into labeled, unlabeled, and test sets\n",
    "    labeled_indices = indices[:num_labeled]\n",
    "    unlabeled_indices = indices[num_labeled: num_labeled + num_unlabeled]\n",
    "    test_indices = indices[num_unlabeled:]\n",
    "\n",
    "    labeled_set_view1 = dataset_view1[labeled_indices]\n",
    "    labeled_set_view2 = dataset_view2[labeled_indices]\n",
    "    label_labeled_set = labels_data[labeled_indices]  # You need to provide the labels\n",
    "\n",
    "    unlabeled_set_view1 = dataset_view1[unlabeled_indices]\n",
    "    unlabeled_set_view2 = dataset_view2[unlabeled_indices]\n",
    "\n",
    "    test_set_view1 = dataset_view1[test_indices]\n",
    "    test_set_view2 = dataset_view2[test_indices]\n",
    "    label_test_set = labels_data[test_indices] \n",
    "    \n",
    "    \n",
    "    return labeled_set_view1, labeled_set_view2, label_labeled_set, unlabeled_set_view1, unlabeled_set_view2, test_set_view1, test_set_view2, label_test_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 26ms/step - loss: 1.3806 - accuracy: 0.5583\n",
      "1/7 [===>..........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srina\\AppData\\Local\\Temp\\ipykernel_19760\\3695694683.py:29: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  classifier2.fit(labeled_set_2_2D, label_labeled_set)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 10ms/step\n",
      "7/7 [==============================] - 0s 11ms/step\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.3200 - accuracy: 0.6500\n",
      "422/422 [==============================] - 6s 13ms/step - loss: 1.7773 - accuracy: 0.7401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srina\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 57ms/step - loss: 1.2149 - accuracy: 0.7083\n",
      " 1/13 [=>............................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srina\\AppData\\Local\\Temp\\ipykernel_19760\\3695694683.py:29: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  classifier2.fit(labeled_set_2_2D, label_labeled_set)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 9ms/step\n",
      "13/13 [==============================] - 0s 8ms/step\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 1.1298 - accuracy: 0.6750\n",
      "416/416 [==============================] - 5s 11ms/step - loss: 1.7434 - accuracy: 0.7403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srina\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 45ms/step - loss: 1.0796 - accuracy: 0.7417\n",
      " 1/19 [>.............................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srina\\AppData\\Local\\Temp\\ipykernel_19760\\3695694683.py:29: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  classifier2.fit(labeled_set_2_2D, label_labeled_set)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 9ms/step\n",
      "19/19 [==============================] - 0s 9ms/step\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.9738 - accuracy: 0.7583\n",
      "409/409 [==============================] - 5s 13ms/step - loss: 1.7109 - accuracy: 0.7403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srina\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Co-training of unlabeled 200 of CNN Accuracy: [1.7773396968841553, 0.7401171922683716] and Random Forest Accuracy: 0.8863012682637396\n",
      "KNN Accuracy for label propogation for 200 unlabeled size: 0.8091670993102426\n",
      "Co-training of unlabeled 400 of CNN Accuracy: [1.743417501449585, 0.7403448224067688] and Random Forest Accuracy: 0.8863208612512233\n",
      "KNN Accuracy for label propogation for 400 unlabeled size: 0.8090039900624859\n",
      "Co-training of unlabeled 600 of CNN Accuracy: [1.7109112739562988, 0.740273654460907] and Random Forest Accuracy: 0.8864174883436521\n",
      "KNN Accuracy for label propogation for 600 unlabeled size: 0.8087594588397157\n"
     ]
    }
   ],
   "source": [
    "labeled_set_1, labeled_set_2, labeled_1, unlabeled_set_1, unlabeled_set_2, test_set_1, test_set_2, test_label_set_1 = Reupdated_split_dataset(view1_data, view2_data, labeled_size= 120, unlabeled_size= 200)\n",
    "\n",
    "labeled_set_3, labeled_set_4, labeled_2, unlabeled_set_3, unlabeled_set_4, test_set_3, test_set_4, test_label_set_2 = Reupdated_split_dataset(view1_data, view2_data, labeled_size= 120, unlabeled_size= 400)\n",
    "\n",
    "labeled_set_5, labeled_set_6, labeled_3, unlabeled_set_5, unlabeled_set_6, test_set_5, test_set_6, test_label_set_3 = Reupdated_split_dataset(view1_data, view2_data, labeled_size= 120, unlabeled_size= 600)\n",
    "\n",
    "cnn_acc_1, rf_acc_1 = co_training(classifier1=cnn_classifier , classifier2=classifier_rf, \n",
    "                                        labeled_set_1=labeled_set_1, labeled_set_2=labeled_set_2,label_labeled_set=labeled_1,\n",
    "                                        unlabeled_set_1=unlabeled_set_1, unlabeled_set_2=unlabeled_set_2,\n",
    "                                        test_set_1=test_set_1, test_set_2=test_set_2, label_test_set=test_label_set_1,\n",
    "                                        threshold_confidence= 0.90)\n",
    "\n",
    "l_prop_accuracy_1 = label_propagation(labeled_set_1, unlabeled_set_1, labeled_1, test_set_1, test_label_set_1, n_neighbors=7)\n",
    "\n",
    "\n",
    "cnn_acc_2, rf_acc_2 = co_training(classifier1=cnn_classifier , classifier2=classifier_rf, \n",
    "                                        labeled_set_1=labeled_set_3, labeled_set_2=labeled_set_4,label_labeled_set=labeled_2,\n",
    "                                        unlabeled_set_1=unlabeled_set_3, unlabeled_set_2=unlabeled_set_4,\n",
    "                                        test_set_1=test_set_3, test_set_2=test_set_4, label_test_set=test_label_set_2,\n",
    "                                        threshold_confidence= 0.90)\n",
    "\n",
    "l_prop_accuracy_2 = label_propagation(labeled_set_3, unlabeled_set_3, labeled_2, test_set_3, test_label_set_2, n_neighbors=7)\n",
    "\n",
    "\n",
    "cnn_acc_3, rf_acc_3 = co_training(classifier1=cnn_classifier , classifier2=classifier_rf, \n",
    "                                        labeled_set_1=labeled_set_5, labeled_set_2=labeled_set_6,label_labeled_set=labeled_3,\n",
    "                                        unlabeled_set_1=unlabeled_set_5, unlabeled_set_2=unlabeled_set_6,\n",
    "                                        test_set_1=test_set_5, test_set_2=test_set_6, label_test_set=test_label_set_3,\n",
    "                                        threshold_confidence= 0.90)\n",
    "\n",
    "l_prop_accuracy_3 = label_propagation(labeled_set_5, unlabeled_set_5, labeled_3, test_set_5, test_label_set_3, n_neighbors=7)\n",
    "\n",
    "\n",
    "print(f\"Co-training of unlabeled 200 of CNN Accuracy: {cnn_acc_1} and Random Forest Accuracy: {rf_acc_1}\")\n",
    "print(f\"KNN Accuracy for label propogation for 200 unlabeled size: {l_prop_accuracy_1}\")\n",
    "print(f\"Co-training of unlabeled 400 of CNN Accuracy: {cnn_acc_2} and Random Forest Accuracy: {rf_acc_2}\")\n",
    "print(f\"KNN Accuracy for label propogation for 400 unlabeled size: {l_prop_accuracy_2}\")\n",
    "print(f\"Co-training of unlabeled 600 of CNN Accuracy: {cnn_acc_3} and Random Forest Accuracy: {rf_acc_3}\")\n",
    "print(f\"KNN Accuracy for label propogation for 600 unlabeled size: {l_prop_accuracy_3}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Submission</h2>\n",
    "\n",
    "<hr style=\"border-top: 5px solid orange; margin-top: 1px; margin-bottom: 1px\"></hr>\n",
    "\n",
    "<p style=\"text-align: justify;\">You need to submit a Jupyter Notebook (*.ipynb) file that contains your completed code.\n",
    "\n",
    "\n",
    "<span>The file name should be in <strong>FirstName_LastName</strong> format</span>.</p>\n",
    "<p style=\"text-align: justify;\"><span>DO NOT INCLUDE EXTRA FILES, SUCH AS THE INPUT DATASETS</span>, in your submission;</p>\n",
    "<p style=\"text-align: justify;\">Please download your assignment after submission and make sure it is not corrupted or empty! We will not be responsible for corrupted submissions and will not take a resubmission after the deadline.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need Help?\n",
    "If you need help with this assignment, please get in touch with TAs via their emails, or go to their office hours.\n",
    "You are highly encouraged to ask your question on the designated channel for Assignment o on Microsoft Teams (not necessarily monitored by the instructor/TAs). Feel free to help other students with general questions. However, DO NOT share your solution.<hr style=\"border-top: 5px solid orange; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
